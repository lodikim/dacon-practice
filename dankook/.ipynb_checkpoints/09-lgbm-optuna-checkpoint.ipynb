{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09-Optuna (using LGBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/003_efficient_optimization_algorithms.html , https://www.kaggle.com/bjoernholzhauer/lightgbm-tuning-with-optuna , https://analyticsindiamag.com/hands-on-python-guide-to-optuna-a-new-hyperparameter-optimization-tool/\n",
    "\n",
    "optuna comes with a generic ability to tune hyperparameters for any machine learning algorithm, but specifically for LightGBM there is an integration via the LightGBMTunerCV function. This function implements a sensible hyperparameter tuning strategy that is known to be sensible for LightGBM by tuning the following parameters in order:\n",
    "\n",
    "feature_fraction\n",
    "num_leaves\n",
    "bagging_fraction and bagging_freq\n",
    "feature_fraction (again)\n",
    "regularization factors (i.e. 'lambda_l1' and 'lambda_l2')\n",
    "min_child_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "import optuna.integration.lightgbm as lgb\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (16, 8)\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('max_columns', 100)\n",
    "pd.set_option(\"display.precision\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../../dacon-inputs/dankook/input')\n",
    "sub_dir = Path('../../dacon-inputs/dankook/sub')\n",
    "feature_dir = Path('../../dacon-inputs/dankook/feature')\n",
    "val_dir = Path('../../dacon-inputs/dankook/val')\n",
    "tst_dir = Path('../../dacon-inputs/dankook/tst')\n",
    "\n",
    "trn_file = data_dir / 'train.csv'\n",
    "tst_file = data_dir / 'test.csv'\n",
    "sample_file = data_dir / 'sample_submission.csv'\n",
    "\n",
    "target_col = 'class'\n",
    "n_fold = 5\n",
    "n_class = 3 # b/c class is 0, 1, 2?\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/bryan/dacon-inputs/dankook/input')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_name = 'lgb_optuna'\n",
    "feature_name = 'feature'\n",
    "model_name = f'{algo_name}_{feature_name}'\n",
    "\n",
    "feature_file = feature_dir / f'{feature_name}.csv'\n",
    "p_val_file = val_dir / f'{model_name}.val.csv'\n",
    "p_tst_file = tst_dir / f'{model_name}.tst.csv'\n",
    "sub_file = sub_dir / f'{model_name}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>redshift</th>\n",
       "      <th>dered_u</th>\n",
       "      <th>dered_g</th>\n",
       "      <th>dered_r</th>\n",
       "      <th>dered_i</th>\n",
       "      <th>dered_z</th>\n",
       "      <th>nObserve</th>\n",
       "      <th>airmass_u</th>\n",
       "      <th>class</th>\n",
       "      <th>d_dered_u</th>\n",
       "      <th>d_dered_g</th>\n",
       "      <th>d_dered_r</th>\n",
       "      <th>d_dered_i</th>\n",
       "      <th>d_dered_z</th>\n",
       "      <th>d_dered_ig</th>\n",
       "      <th>d_dered_zg</th>\n",
       "      <th>d_dered_rz</th>\n",
       "      <th>d_dered_iz</th>\n",
       "      <th>d_obs_det</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.9396</td>\n",
       "      <td>-8.1086e-05</td>\n",
       "      <td>23.1243</td>\n",
       "      <td>20.2578</td>\n",
       "      <td>18.9551</td>\n",
       "      <td>17.6321</td>\n",
       "      <td>16.9089</td>\n",
       "      <td>2.9444</td>\n",
       "      <td>1.1898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1397</td>\n",
       "      <td>-0.0790</td>\n",
       "      <td>-0.0544</td>\n",
       "      <td>-0.0403</td>\n",
       "      <td>-0.0307</td>\n",
       "      <td>-2.6257</td>\n",
       "      <td>-3.3488</td>\n",
       "      <td>2.0462</td>\n",
       "      <td>0.7232</td>\n",
       "      <td>-15.0556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.1689</td>\n",
       "      <td>4.5061e-03</td>\n",
       "      <td>14.9664</td>\n",
       "      <td>14.0045</td>\n",
       "      <td>13.4114</td>\n",
       "      <td>13.2363</td>\n",
       "      <td>13.1347</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>1.2533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0857</td>\n",
       "      <td>-0.0574</td>\n",
       "      <td>-0.0410</td>\n",
       "      <td>-0.0322</td>\n",
       "      <td>-0.0343</td>\n",
       "      <td>-0.7683</td>\n",
       "      <td>-0.8698</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>-0.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.3500</td>\n",
       "      <td>4.7198e-04</td>\n",
       "      <td>16.6076</td>\n",
       "      <td>15.6866</td>\n",
       "      <td>15.4400</td>\n",
       "      <td>15.3217</td>\n",
       "      <td>15.2961</td>\n",
       "      <td>1.0986</td>\n",
       "      <td>1.0225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1787</td>\n",
       "      <td>-0.1388</td>\n",
       "      <td>-0.0963</td>\n",
       "      <td>-0.0718</td>\n",
       "      <td>-0.0540</td>\n",
       "      <td>-0.3649</td>\n",
       "      <td>-0.3905</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>-0.9014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.6346</td>\n",
       "      <td>5.8143e-06</td>\n",
       "      <td>25.3536</td>\n",
       "      <td>20.9947</td>\n",
       "      <td>20.0873</td>\n",
       "      <td>19.7947</td>\n",
       "      <td>19.5552</td>\n",
       "      <td>1.6094</td>\n",
       "      <td>1.2054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.3070</td>\n",
       "      <td>-0.1941</td>\n",
       "      <td>-0.1339</td>\n",
       "      <td>-0.1003</td>\n",
       "      <td>-0.0795</td>\n",
       "      <td>-1.2000</td>\n",
       "      <td>-1.4395</td>\n",
       "      <td>0.5321</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>-1.3906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.9826</td>\n",
       "      <td>-3.3247e-05</td>\n",
       "      <td>23.7714</td>\n",
       "      <td>20.4338</td>\n",
       "      <td>18.8630</td>\n",
       "      <td>18.1903</td>\n",
       "      <td>17.8759</td>\n",
       "      <td>2.6391</td>\n",
       "      <td>1.1939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.6820</td>\n",
       "      <td>-0.2653</td>\n",
       "      <td>-0.1794</td>\n",
       "      <td>-0.1339</td>\n",
       "      <td>-0.1067</td>\n",
       "      <td>-2.2436</td>\n",
       "      <td>-2.5579</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.3144</td>\n",
       "      <td>-9.3609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          z    redshift  dered_u  dered_g  dered_r  dered_i  dered_z  \\\n",
       "id                                                                     \n",
       "0   16.9396 -8.1086e-05  23.1243  20.2578  18.9551  17.6321  16.9089   \n",
       "1   13.1689  4.5061e-03  14.9664  14.0045  13.4114  13.2363  13.1347   \n",
       "2   15.3500  4.7198e-04  16.6076  15.6866  15.4400  15.3217  15.2961   \n",
       "3   19.6346  5.8143e-06  25.3536  20.9947  20.0873  19.7947  19.5552   \n",
       "4   17.9826 -3.3247e-05  23.7714  20.4338  18.8630  18.1903  17.8759   \n",
       "\n",
       "    nObserve  airmass_u  class  d_dered_u  d_dered_g  d_dered_r  d_dered_i  \\\n",
       "id                                                                           \n",
       "0     2.9444     1.1898    0.0    -0.1397    -0.0790    -0.0544    -0.0403   \n",
       "1     0.6931     1.2533    1.0    -0.0857    -0.0574    -0.0410    -0.0322   \n",
       "2     1.0986     1.0225    0.0    -0.1787    -0.1388    -0.0963    -0.0718   \n",
       "3     1.6094     1.2054    0.0    -0.3070    -0.1941    -0.1339    -0.1003   \n",
       "4     2.6391     1.1939    0.0    -0.6820    -0.2653    -0.1794    -0.1339   \n",
       "\n",
       "    d_dered_z  d_dered_ig  d_dered_zg  d_dered_rz  d_dered_iz  d_obs_det  \n",
       "id                                                                        \n",
       "0     -0.0307     -2.6257     -3.3488      2.0462      0.7232   -15.0556  \n",
       "1     -0.0343     -0.7683     -0.8698      0.2767      0.1016    -0.3069  \n",
       "2     -0.0540     -0.3649     -0.3905      0.1440      0.0257    -0.9014  \n",
       "3     -0.0795     -1.2000     -1.4395      0.5321      0.2395    -1.3906  \n",
       "4     -0.1067     -2.2436     -2.5579      0.9871      0.3144    -9.3609  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(feature_file, index_col=0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320000,) (320000, 19) (80000, 19)\n"
     ]
    }
   ],
   "source": [
    "y = df[target_col].values[:320000]\n",
    "df.drop(target_col, axis=1, inplace=True)\n",
    "trn = df.iloc[:320000].values\n",
    "tst = df.iloc[320000:].values\n",
    "feature_name = df.columns.tolist()\n",
    "print(y.shape, trn.shape, tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, X_val, y_trn, y_val = train_test_split(trn, y, test_size=.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"multiclass\",\n",
    "    \"metric\": \"multi_logloss\",\n",
    "    \"num_class\": 3,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"subsample_freq\": 1,\n",
    "    \"lambda_l1\": 0.,\n",
    "    \"lambda_l2\": 0.,\n",
    "    \"random_state\": seed,\n",
    "    \"n_jobs\": -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-14 20:59:28,199]\u001b[0m A new study created in memory with name: no-name-d18b0a5d-a191-4751-a9a0-1a7eb536c481\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.170962:  14%|######4                                      | 1/7 [00:10<01:04, 10.74s/it]\u001b[32m[I 2021-08-14 20:59:38,962]\u001b[0m Trial 0 finished with value: 0.17096175636534103 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.17096175636534103.\u001b[0m\n",
      "feature_fraction, val_score: 0.170962:  14%|######4                                      | 1/7 [00:10<01:04, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's multi_logloss: 0.158753\tvalid_1's multi_logloss: 0.170962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.158717\tvalid_1's multi_logloss: 0.17132\n",
      "[200]\tvalid_0's multi_logloss: 0.143188\tvalid_1's multi_logloss: 0.166106\n",
      "[300]\tvalid_0's multi_logloss: 0.133515\tvalid_1's multi_logloss: 0.164868\n",
      "[400]\tvalid_0's multi_logloss: 0.125581\tvalid_1's multi_logloss: 0.164113\n",
      "Early stopping, best iteration is:\n",
      "[440]\tvalid_0's multi_logloss: 0.122699\tvalid_1's multi_logloss: 0.163875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.163875:  29%|############8                                | 2/7 [00:50<02:17, 27.57s/it]\u001b[32m[I 2021-08-14 21:00:18,311]\u001b[0m Trial 1 finished with value: 0.1638750687578173 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.1638750687578173.\u001b[0m\n",
      "feature_fraction, val_score: 0.163875:  29%|############8                                | 2/7 [00:50<02:17, 27.57s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.155774\tvalid_1's multi_logloss: 0.169529\n",
      "[200]\tvalid_0's multi_logloss: 0.141269\tvalid_1's multi_logloss: 0.165328\n",
      "[300]\tvalid_0's multi_logloss: 0.13149\tvalid_1's multi_logloss: 0.164003\n",
      "[400]\tvalid_0's multi_logloss: 0.123577\tvalid_1's multi_logloss: 0.163539\n",
      "Early stopping, best iteration is:\n",
      "[390]\tvalid_0's multi_logloss: 0.124258\tvalid_1's multi_logloss: 0.163535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.163535:  43%|###################2                         | 3/7 [01:27<02:08, 32.18s/it]\u001b[32m[I 2021-08-14 21:00:55,979]\u001b[0m Trial 2 finished with value: 0.16353543107276666 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.16353543107276666.\u001b[0m\n",
      "feature_fraction, val_score: 0.163535:  43%|###################2                         | 3/7 [01:27<02:08, 32.18s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.163535:  57%|#########################7                   | 4/7 [01:39<01:11, 23.96s/it]\u001b[32m[I 2021-08-14 21:01:07,345]\u001b[0m Trial 3 finished with value: 0.1706718619030583 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.16353543107276666.\u001b[0m\n",
      "feature_fraction, val_score: 0.163535:  57%|#########################7                   | 4/7 [01:39<01:11, 23.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's multi_logloss: 0.158623\tvalid_1's multi_logloss: 0.170672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.154919\tvalid_1's multi_logloss: 0.170396\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's multi_logloss: 0.156424\tvalid_1's multi_logloss: 0.169923"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.163535:  71%|################################1            | 5/7 [01:50<00:38, 19.49s/it]\u001b[32m[I 2021-08-14 21:01:18,898]\u001b[0m Trial 4 finished with value: 0.16992265061997314 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.16353543107276666.\u001b[0m\n",
      "feature_fraction, val_score: 0.163535:  71%|################################1            | 5/7 [01:50<00:38, 19.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.16272\tvalid_1's multi_logloss: 0.174574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.163535:  86%|######################################5      | 6/7 [02:05<00:18, 18.03s/it]\u001b[32m[I 2021-08-14 21:01:34,088]\u001b[0m Trial 5 finished with value: 0.17008600818295716 and parameters: {'feature_fraction': 0.4}. Best is trial 2 with value: 0.16353543107276666.\u001b[0m\n",
      "feature_fraction, val_score: 0.163535:  86%|######################################5      | 6/7 [02:05<00:18, 18.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's multi_logloss: 0.153295\tvalid_1's multi_logloss: 0.170086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.157483\tvalid_1's multi_logloss: 0.170786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.163535: 100%|#############################################| 7/7 [02:17<00:00, 16.00s/it]\u001b[32m[I 2021-08-14 21:01:45,924]\u001b[0m Trial 6 finished with value: 0.170664117564035 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.16353543107276666.\u001b[0m\n",
      "feature_fraction, val_score: 0.163535: 100%|#############################################| 7/7 [02:17<00:00, 19.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's multi_logloss: 0.157261\tvalid_1's multi_logloss: 0.170664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.163535:   0%|                                                          | 0/20 [00:00<?, ?it/s]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.103417\tvalid_1's multi_logloss: 0.163112\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.0975406\tvalid_1's multi_logloss: 0.163037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.163037:   5%|##5                                               | 1/20 [00:26<08:23, 26.48s/it]\u001b[32m[I 2021-08-14 21:02:12,417]\u001b[0m Trial 7 finished with value: 0.16303659334534812 and parameters: {'num_leaves': 212}. Best is trial 7 with value: 0.16303659334534812.\u001b[0m\n",
      "num_leaves, val_score: 0.163037:   5%|##5                                               | 1/20 [00:26<08:23, 26.48s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.120394\tvalid_1's multi_logloss: 0.16366\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's multi_logloss: 0.110859\tvalid_1's multi_logloss: 0.163319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.163037:  10%|#####                                             | 2/20 [00:49<07:19, 24.39s/it]\u001b[32m[I 2021-08-14 21:02:35,347]\u001b[0m Trial 8 finished with value: 0.16331914164038525 and parameters: {'num_leaves': 133}. Best is trial 7 with value: 0.16303659334534812.\u001b[0m\n",
      "num_leaves, val_score: 0.163037:  10%|#####                                             | 2/20 [00:49<07:19, 24.39s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.123817\tvalid_1's multi_logloss: 0.163727\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's multi_logloss: 0.114809\tvalid_1's multi_logloss: 0.163019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.163019:  15%|#######5                                          | 3/20 [01:12<06:45, 23.88s/it]\u001b[32m[I 2021-08-14 21:02:58,608]\u001b[0m Trial 9 finished with value: 0.16301943292894944 and parameters: {'num_leaves': 119}. Best is trial 9 with value: 0.16301943292894944.\u001b[0m\n",
      "num_leaves, val_score: 0.163019:  15%|#######5                                          | 3/20 [01:12<06:45, 23.88s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.187751\tvalid_1's multi_logloss: 0.19218\n",
      "[200]\tvalid_0's multi_logloss: 0.171533\tvalid_1's multi_logloss: 0.178355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.163019:  20%|##########                                        | 4/20 [01:31<05:47, 21.71s/it]\u001b[32m[I 2021-08-14 21:03:17,009]\u001b[0m Trial 10 finished with value: 0.17667085475848565 and parameters: {'num_leaves': 8}. Best is trial 9 with value: 0.16301943292894944.\u001b[0m\n",
      "num_leaves, val_score: 0.163019:  20%|##########                                        | 4/20 [01:31<05:47, 21.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's multi_logloss: 0.168893\tvalid_1's multi_logloss: 0.176671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.158818\tvalid_1's multi_logloss: 0.17115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.163019:  25%|############5                                     | 5/20 [01:43<04:33, 18.22s/it]\u001b[32m[I 2021-08-14 21:03:29,040]\u001b[0m Trial 11 finished with value: 0.17096139946939365 and parameters: {'num_leaves': 27}. Best is trial 9 with value: 0.16301943292894944.\u001b[0m\n",
      "num_leaves, val_score: 0.163019:  25%|############5                                     | 5/20 [01:43<04:33, 18.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.157647\tvalid_1's multi_logloss: 0.170961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.111415\tvalid_1's multi_logloss: 0.163285\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's multi_logloss: 0.108859\tvalid_1's multi_logloss: 0.163186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.163019:  30%|###############                                   | 6/20 [02:05<04:34, 19.58s/it]\u001b[32m[I 2021-08-14 21:03:51,269]\u001b[0m Trial 12 finished with value: 0.16318628324565326 and parameters: {'num_leaves': 172}. Best is trial 9 with value: 0.16301943292894944.\u001b[0m\n",
      "num_leaves, val_score: 0.163019:  30%|###############                                   | 6/20 [02:05<04:34, 19.58s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021957 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.13689\tvalid_1's multi_logloss: 0.164788\n",
      "[200]\tvalid_0's multi_logloss: 0.116775\tvalid_1's multi_logloss: 0.163367\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's multi_logloss: 0.112884\tvalid_1's multi_logloss: 0.163202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.163019:  35%|#################5                                | 7/20 [02:33<04:52, 22.53s/it]\u001b[32m[I 2021-08-14 21:04:19,858]\u001b[0m Trial 13 finished with value: 0.16320170419196237 and parameters: {'num_leaves': 74}. Best is trial 9 with value: 0.16301943292894944.\u001b[0m\n",
      "num_leaves, val_score: 0.163019:  35%|#################5                                | 7/20 [02:33<04:52, 22.53s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.121639\tvalid_1's multi_logloss: 0.163396\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's multi_logloss: 0.114445\tvalid_1's multi_logloss: 0.163075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.163019:  40%|####################                              | 8/20 [02:55<04:25, 22.09s/it]\u001b[32m[I 2021-08-14 21:04:40,997]\u001b[0m Trial 14 finished with value: 0.16307472213970817 and parameters: {'num_leaves': 127}. Best is trial 9 with value: 0.16301943292894944.\u001b[0m\n",
      "num_leaves, val_score: 0.163019:  40%|####################                              | 8/20 [02:55<04:25, 22.09s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.108386\tvalid_1's multi_logloss: 0.163009\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 0.106446\tvalid_1's multi_logloss: 0.162913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162913:  45%|######################5                           | 9/20 [03:17<04:05, 22.35s/it]\u001b[32m[I 2021-08-14 21:05:03,935]\u001b[0m Trial 15 finished with value: 0.16291271716009226 and parameters: {'num_leaves': 187}. Best is trial 15 with value: 0.16291271716009226.\u001b[0m\n",
      "num_leaves, val_score: 0.162913:  45%|######################5                           | 9/20 [03:18<04:05, 22.35s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.135142\tvalid_1's multi_logloss: 0.164743\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 0.119491\tvalid_1's multi_logloss: 0.163556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162913:  50%|########################5                        | 10/20 [03:42<03:49, 22.95s/it]\u001b[32m[I 2021-08-14 21:05:28,234]\u001b[0m Trial 16 finished with value: 0.16355643398054515 and parameters: {'num_leaves': 80}. Best is trial 15 with value: 0.16291271716009226.\u001b[0m\n",
      "num_leaves, val_score: 0.162913:  50%|########################5                        | 10/20 [03:42<03:49, 22.95s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.0966405\tvalid_1's multi_logloss: 0.162827\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.0923219\tvalid_1's multi_logloss: 0.162791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162791:  55%|##########################9                      | 11/20 [04:30<04:35, 30.61s/it]\u001b[32m[I 2021-08-14 21:06:16,211]\u001b[0m Trial 17 finished with value: 0.16279106594387957 and parameters: {'num_leaves': 250}. Best is trial 17 with value: 0.16279106594387957.\u001b[0m\n",
      "num_leaves, val_score: 0.162791:  55%|##########################9                      | 11/20 [04:30<04:35, 30.61s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.0985166\tvalid_1's multi_logloss: 0.162786\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 0.0963081\tvalid_1's multi_logloss: 0.162695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162695:  60%|#############################4                   | 12/20 [04:58<03:58, 29.76s/it]\u001b[32m[I 2021-08-14 21:06:44,023]\u001b[0m Trial 18 finished with value: 0.1626952277881318 and parameters: {'num_leaves': 241}. Best is trial 18 with value: 0.1626952277881318.\u001b[0m\n",
      "num_leaves, val_score: 0.162695:  60%|#############################4                   | 12/20 [04:58<03:58, 29.76s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.0969114\tvalid_1's multi_logloss: 0.162853\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's multi_logloss: 0.101601\tvalid_1's multi_logloss: 0.162817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162695:  65%|###############################8                 | 13/20 [05:26<03:25, 29.32s/it]\u001b[32m[I 2021-08-14 21:07:12,334]\u001b[0m Trial 19 finished with value: 0.16281663148912087 and parameters: {'num_leaves': 248}. Best is trial 18 with value: 0.1626952277881318.\u001b[0m\n",
      "num_leaves, val_score: 0.162695:  65%|###############################8                 | 13/20 [05:26<03:25, 29.32s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.0956288\tvalid_1's multi_logloss: 0.163318\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's multi_logloss: 0.09646\tvalid_1's multi_logloss: 0.163277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162695:  70%|##################################3              | 14/20 [05:59<03:02, 30.46s/it]\u001b[32m[I 2021-08-14 21:07:45,428]\u001b[0m Trial 20 finished with value: 0.1632770277578471 and parameters: {'num_leaves': 256}. Best is trial 18 with value: 0.1626952277881318.\u001b[0m\n",
      "num_leaves, val_score: 0.162695:  70%|##################################3              | 14/20 [05:59<03:02, 30.46s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.102624\tvalid_1's multi_logloss: 0.16293\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's multi_logloss: 0.0991651\tvalid_1's multi_logloss: 0.162811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162695:  75%|####################################7            | 15/20 [06:28<02:29, 30.00s/it]\u001b[32m[I 2021-08-14 21:08:14,352]\u001b[0m Trial 21 finished with value: 0.1628109352510602 and parameters: {'num_leaves': 216}. Best is trial 18 with value: 0.1626952277881318.\u001b[0m\n",
      "num_leaves, val_score: 0.162695:  75%|####################################7            | 15/20 [06:28<02:29, 30.00s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.101468\tvalid_1's multi_logloss: 0.162703\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 0.0994242\tvalid_1's multi_logloss: 0.162567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162567:  80%|#######################################2         | 16/20 [06:56<01:57, 29.29s/it]\u001b[32m[I 2021-08-14 21:08:42,006]\u001b[0m Trial 22 finished with value: 0.16256711593671827 and parameters: {'num_leaves': 223}. Best is trial 22 with value: 0.16256711593671827.\u001b[0m\n",
      "num_leaves, val_score: 0.162567:  80%|#######################################2         | 16/20 [06:56<01:57, 29.29s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.1116\tvalid_1's multi_logloss: 0.162716\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.106382\tvalid_1's multi_logloss: 0.162523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162523:  85%|#########################################6       | 17/20 [07:43<01:44, 34.83s/it]\u001b[32m[I 2021-08-14 21:09:29,720]\u001b[0m Trial 23 finished with value: 0.16252305666946737 and parameters: {'num_leaves': 171}. Best is trial 23 with value: 0.16252305666946737.\u001b[0m\n",
      "num_leaves, val_score: 0.162523:  85%|#########################################6       | 17/20 [07:43<01:44, 34.83s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.112383\tvalid_1's multi_logloss: 0.163368\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's multi_logloss: 0.109731\tvalid_1's multi_logloss: 0.163155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162523:  90%|############################################1    | 18/20 [08:08<01:03, 31.82s/it]\u001b[32m[I 2021-08-14 21:09:54,524]\u001b[0m Trial 24 finished with value: 0.1631548255556496 and parameters: {'num_leaves': 167}. Best is trial 23 with value: 0.16252305666946737.\u001b[0m\n",
      "num_leaves, val_score: 0.162523:  90%|############################################1    | 18/20 [08:08<01:03, 31.82s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.105662\tvalid_1's multi_logloss: 0.1627\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.105662\tvalid_1's multi_logloss: 0.1627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162523:  95%|##############################################5  | 19/20 [08:36<00:30, 30.54s/it]\u001b[32m[I 2021-08-14 21:10:22,096]\u001b[0m Trial 25 finished with value: 0.16270018436972317 and parameters: {'num_leaves': 202}. Best is trial 23 with value: 0.16252305666946737.\u001b[0m\n",
      "num_leaves, val_score: 0.162523:  95%|##############################################5  | 19/20 [08:36<00:30, 30.54s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.115205\tvalid_1's multi_logloss: 0.163155\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's multi_logloss: 0.10246\tvalid_1's multi_logloss: 0.162864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.162523: 100%|#################################################| 20/20 [09:07<00:00, 30.72s/it]\u001b[32m[I 2021-08-14 21:10:53,239]\u001b[0m Trial 26 finished with value: 0.16286362141312977 and parameters: {'num_leaves': 155}. Best is trial 23 with value: 0.16252305666946737.\u001b[0m\n",
      "num_leaves, val_score: 0.162523: 100%|#################################################| 20/20 [09:07<00:00, 27.37s/it]\n",
      "bagging, val_score: 0.162523:   0%|                                                             | 0/10 [00:00<?, ?it/s]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.111219\tvalid_1's multi_logloss: 0.162728\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 0.104797\tvalid_1's multi_logloss: 0.16258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162523:  10%|#####3                                               | 1/10 [00:32<04:52, 32.47s/it]\u001b[32m[I 2021-08-14 21:11:25,724]\u001b[0m Trial 27 finished with value: 0.16257976729460313 and parameters: {'bagging_fraction': 0.9690525168127192, 'bagging_freq': 2}. Best is trial 27 with value: 0.16257976729460313.\u001b[0m\n",
      "bagging, val_score: 0.162523:  10%|#####3                                               | 1/10 [00:32<04:52, 32.47s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.114158\tvalid_1's multi_logloss: 0.16543\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's multi_logloss: 0.116773\tvalid_1's multi_logloss: 0.165311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162523:  20%|##########6                                          | 2/10 [00:55<03:35, 26.93s/it]\u001b[32m[I 2021-08-14 21:11:48,777]\u001b[0m Trial 28 finished with value: 0.16531116992217396 and parameters: {'bagging_fraction': 0.4095779810906246, 'bagging_freq': 3}. Best is trial 27 with value: 0.16257976729460313.\u001b[0m\n",
      "bagging, val_score: 0.162523:  20%|##########6                                          | 2/10 [00:55<03:35, 26.93s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.111508\tvalid_1's multi_logloss: 0.16289\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 0.105144\tvalid_1's multi_logloss: 0.162696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162523:  30%|###############9                                     | 3/10 [01:22<03:10, 27.16s/it]\u001b[32m[I 2021-08-14 21:12:16,223]\u001b[0m Trial 29 finished with value: 0.16269585907856624 and parameters: {'bagging_fraction': 0.9553445483226095, 'bagging_freq': 1}. Best is trial 27 with value: 0.16257976729460313.\u001b[0m\n",
      "bagging, val_score: 0.162523:  30%|###############9                                     | 3/10 [01:22<03:10, 27.16s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.111426\tvalid_1's multi_logloss: 0.16296\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's multi_logloss: 0.11335\tvalid_1's multi_logloss: 0.162905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162523:  40%|#####################2                               | 4/10 [01:48<02:38, 26.35s/it]\u001b[32m[I 2021-08-14 21:12:41,309]\u001b[0m Trial 30 finished with value: 0.16290497317006614 and parameters: {'bagging_fraction': 0.7951262224146116, 'bagging_freq': 2}. Best is trial 27 with value: 0.16257976729460313.\u001b[0m\n",
      "bagging, val_score: 0.162523:  40%|#####################2                               | 4/10 [01:48<02:38, 26.35s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.112368\tvalid_1's multi_logloss: 0.163514\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.108569\tvalid_1's multi_logloss: 0.163512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162523:  50%|##########################5                          | 5/10 [02:36<02:50, 34.15s/it]\u001b[32m[I 2021-08-14 21:13:29,286]\u001b[0m Trial 31 finished with value: 0.16351154213432748 and parameters: {'bagging_fraction': 0.6661547003531685, 'bagging_freq': 7}. Best is trial 27 with value: 0.16257976729460313.\u001b[0m\n",
      "bagging, val_score: 0.162523:  50%|##########################5                          | 5/10 [02:36<02:50, 34.15s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.111376\tvalid_1's multi_logloss: 0.162824\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.107569\tvalid_1's multi_logloss: 0.162638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162523:  60%|###############################8                     | 6/10 [03:03<02:07, 31.87s/it]\u001b[32m[I 2021-08-14 21:13:56,743]\u001b[0m Trial 32 finished with value: 0.16263812007793907 and parameters: {'bagging_fraction': 0.8437638569524137, 'bagging_freq': 2}. Best is trial 27 with value: 0.16257976729460313.\u001b[0m\n",
      "bagging, val_score: 0.162523:  60%|###############################8                     | 6/10 [03:03<02:07, 31.87s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.11185\tvalid_1's multi_logloss: 0.162825\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.109508\tvalid_1's multi_logloss: 0.162702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162523:  70%|#####################################                | 7/10 [03:28<01:28, 29.58s/it]\u001b[32m[I 2021-08-14 21:14:21,591]\u001b[0m Trial 33 finished with value: 0.16270227692243786 and parameters: {'bagging_fraction': 0.7710678718070827, 'bagging_freq': 7}. Best is trial 27 with value: 0.16257976729460313.\u001b[0m\n",
      "bagging, val_score: 0.162523:  70%|#####################################                | 7/10 [03:28<01:28, 29.58s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.111198\tvalid_1's multi_logloss: 0.163172\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.108106\tvalid_1's multi_logloss: 0.163053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162523:  80%|##########################################4          | 8/10 [03:56<00:58, 29.25s/it]\u001b[32m[I 2021-08-14 21:14:50,149]\u001b[0m Trial 34 finished with value: 0.1630534201650314 and parameters: {'bagging_fraction': 0.9349754498124196, 'bagging_freq': 5}. Best is trial 27 with value: 0.16257976729460313.\u001b[0m\n",
      "bagging, val_score: 0.162523:  80%|##########################################4          | 8/10 [03:56<00:58, 29.25s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.111444\tvalid_1's multi_logloss: 0.162767\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's multi_logloss: 0.106426\tvalid_1's multi_logloss: 0.16263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162523:  90%|###############################################7     | 9/10 [04:23<00:28, 28.39s/it]\u001b[32m[I 2021-08-14 21:15:16,648]\u001b[0m Trial 35 finished with value: 0.16262958025136856 and parameters: {'bagging_fraction': 0.8849073734262468, 'bagging_freq': 3}. Best is trial 27 with value: 0.16257976729460313.\u001b[0m\n",
      "bagging, val_score: 0.162523:  90%|###############################################7     | 9/10 [04:23<00:28, 28.39s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.027582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.113356\tvalid_1's multi_logloss: 0.164465\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's multi_logloss: 0.112183\tvalid_1's multi_logloss: 0.164382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.162523: 100%|####################################################| 10/10 [04:48<00:00, 27.49s/it]\u001b[32m[I 2021-08-14 21:15:42,117]\u001b[0m Trial 36 finished with value: 0.16438229513923305 and parameters: {'bagging_fraction': 0.5386060537487211, 'bagging_freq': 6}. Best is trial 27 with value: 0.16257976729460313.\u001b[0m\n",
      "bagging, val_score: 0.162523: 100%|####################################################| 10/10 [04:48<00:00, 28.89s/it]\n",
      "feature_fraction_stage2, val_score: 0.162523:   0%|                                              | 0/6 [00:00<?, ?it/s]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110455\tvalid_1's multi_logloss: 0.162837\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's multi_logloss: 0.105399\tvalid_1's multi_logloss: 0.162729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162523:  17%|######3                               | 1/6 [00:26<02:13, 26.63s/it]\u001b[32m[I 2021-08-14 21:16:08,760]\u001b[0m Trial 37 finished with value: 0.1627285101874528 and parameters: {'feature_fraction': 0.7799999999999999}. Best is trial 37 with value: 0.1627285101874528.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162523:  17%|######3                               | 1/6 [00:26<02:13, 26.63s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.1116\tvalid_1's multi_logloss: 0.162716\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.106382\tvalid_1's multi_logloss: 0.162523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162523:  33%|############6                         | 2/6 [00:57<01:55, 28.99s/it]\u001b[32m[I 2021-08-14 21:16:39,401]\u001b[0m Trial 38 finished with value: 0.16252305666946737 and parameters: {'feature_fraction': 0.6839999999999999}. Best is trial 38 with value: 0.16252305666946737.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162523:  33%|############6                         | 2/6 [00:57<01:55, 28.99s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110874\tvalid_1's multi_logloss: 0.163427\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.10554\tvalid_1's multi_logloss: 0.163274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162523:  50%|###################                   | 3/6 [01:23<01:23, 27.76s/it]\u001b[32m[I 2021-08-14 21:17:05,706]\u001b[0m Trial 39 finished with value: 0.1632740482066618 and parameters: {'feature_fraction': 0.716}. Best is trial 38 with value: 0.16252305666946737.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162523:  50%|###################                   | 3/6 [01:23<01:23, 27.76s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.110874\tvalid_1's multi_logloss: 0.163427\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.10554\tvalid_1's multi_logloss: 0.163274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162523:  67%|#########################3            | 4/6 [01:50<00:54, 27.28s/it]\u001b[32m[I 2021-08-14 21:17:32,248]\u001b[0m Trial 40 finished with value: 0.1632740482066618 and parameters: {'feature_fraction': 0.748}. Best is trial 38 with value: 0.16252305666946737.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162523:  67%|#########################3            | 4/6 [01:50<00:54, 27.28s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.11241\tvalid_1's multi_logloss: 0.162693\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.107103\tvalid_1's multi_logloss: 0.162435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162435:  83%|###############################6      | 5/6 [02:16<00:26, 26.89s/it]\u001b[32m[I 2021-08-14 21:17:58,432]\u001b[0m Trial 41 finished with value: 0.16243497519347402 and parameters: {'feature_fraction': 0.652}. Best is trial 41 with value: 0.16243497519347402.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162435:  83%|###############################6      | 5/6 [02:16<00:26, 26.89s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.11241\tvalid_1's multi_logloss: 0.162693\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.107103\tvalid_1's multi_logloss: 0.162435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.162435: 100%|######################################| 6/6 [02:42<00:00, 26.51s/it]\u001b[32m[I 2021-08-14 21:18:24,212]\u001b[0m Trial 42 finished with value: 0.16243497519347402 and parameters: {'feature_fraction': 0.62}. Best is trial 41 with value: 0.16243497519347402.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.162435: 100%|######################################| 6/6 [02:42<00:00, 27.01s/it]\n",
      "regularization_factors, val_score: 0.162435:   0%|                                              | 0/20 [00:00<?, ?it/s]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.113648\tvalid_1's multi_logloss: 0.162978\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's multi_logloss: 0.104416\tvalid_1's multi_logloss: 0.162731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162435:   5%|#9                                    | 1/20 [00:28<09:01, 28.49s/it]\u001b[32m[I 2021-08-14 21:18:52,721]\u001b[0m Trial 43 finished with value: 0.16273102888944949 and parameters: {'lambda_l1': 0.28488681206542266, 'lambda_l2': 0.0007181759702945752}. Best is trial 43 with value: 0.16273102888944949.\u001b[0m\n",
      "regularization_factors, val_score: 0.162435:   5%|#9                                    | 1/20 [00:28<09:01, 28.49s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.112597\tvalid_1's multi_logloss: 0.162591\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.109248\tvalid_1's multi_logloss: 0.162424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162424:  10%|###8                                  | 2/20 [00:53<07:59, 26.63s/it]\u001b[32m[I 2021-08-14 21:19:18,042]\u001b[0m Trial 44 finished with value: 0.16242387494567667 and parameters: {'lambda_l1': 1.5673282051389294e-05, 'lambda_l2': 0.0015787631931333075}. Best is trial 44 with value: 0.16242387494567667.\u001b[0m\n",
      "regularization_factors, val_score: 0.162424:  10%|###8                                  | 2/20 [00:53<07:59, 26.63s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.112547\tvalid_1's multi_logloss: 0.162961\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's multi_logloss: 0.107821\tvalid_1's multi_logloss: 0.162757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162424:  15%|#####7                                | 3/20 [01:23<08:00, 28.24s/it]\u001b[32m[I 2021-08-14 21:19:48,209]\u001b[0m Trial 45 finished with value: 0.16275746164219618 and parameters: {'lambda_l1': 0.00012193137324933736, 'lambda_l2': 5.30026506569583e-07}. Best is trial 44 with value: 0.16242387494567667.\u001b[0m\n",
      "regularization_factors, val_score: 0.162424:  15%|#####7                                | 3/20 [01:23<08:00, 28.24s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.113337\tvalid_1's multi_logloss: 0.162592\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.109692\tvalid_1's multi_logloss: 0.162321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.162321:  20%|#######6                              | 4/20 [01:52<07:33, 28.34s/it]\u001b[32m[I 2021-08-14 21:20:16,694]\u001b[0m Trial 46 finished with value: 0.16232128311674276 and parameters: {'lambda_l1': 0.05402143625772734, 'lambda_l2': 0.11207897702764302}. Best is trial 46 with value: 0.16232128311674276.\u001b[0m\n",
      "regularization_factors, val_score: 0.162321:  20%|#######6                              | 4/20 [01:52<07:33, 28.34s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.119044\tvalid_1's multi_logloss: 0.162452\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's multi_logloss: 0.111012\tvalid_1's multi_logloss: 0.161973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161973:  25%|#########5                            | 5/20 [02:20<07:03, 28.21s/it]\u001b[32m[I 2021-08-14 21:20:44,669]\u001b[0m Trial 47 finished with value: 0.16197297544408445 and parameters: {'lambda_l1': 0.006405451653757758, 'lambda_l2': 2.9060967859785816}. Best is trial 47 with value: 0.16197297544408445.\u001b[0m\n",
      "regularization_factors, val_score: 0.161973:  25%|#########5                            | 5/20 [02:20<07:03, 28.21s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.029423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.112664\tvalid_1's multi_logloss: 0.162533\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.109282\tvalid_1's multi_logloss: 0.16238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161973:  30%|###########4                          | 6/20 [02:44<06:16, 26.92s/it]\u001b[32m[I 2021-08-14 21:21:09,078]\u001b[0m Trial 48 finished with value: 0.162380463463676 and parameters: {'lambda_l1': 4.891834636774069e-07, 'lambda_l2': 1.0814630827278064e-05}. Best is trial 47 with value: 0.16197297544408445.\u001b[0m\n",
      "regularization_factors, val_score: 0.161973:  30%|###########4                          | 6/20 [02:44<06:16, 26.92s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.112434\tvalid_1's multi_logloss: 0.162601\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 0.106521\tvalid_1's multi_logloss: 0.162348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161973:  35%|#############3                        | 7/20 [03:11<05:47, 26.70s/it]\u001b[32m[I 2021-08-14 21:21:35,342]\u001b[0m Trial 49 finished with value: 0.16234792511080956 and parameters: {'lambda_l1': 0.00034057937718780105, 'lambda_l2': 3.3494109013642103e-06}. Best is trial 47 with value: 0.16197297544408445.\u001b[0m\n",
      "regularization_factors, val_score: 0.161973:  35%|#############3                        | 7/20 [03:11<05:47, 26.70s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.115736\tvalid_1's multi_logloss: 0.163136\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's multi_logloss: 0.107375\tvalid_1's multi_logloss: 0.162772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161973:  40%|###############2                      | 8/20 [03:38<05:24, 27.06s/it]\u001b[32m[I 2021-08-14 21:22:03,150]\u001b[0m Trial 50 finished with value: 0.1627723457581133 and parameters: {'lambda_l1': 0.0019386161947085273, 'lambda_l2': 0.8841781018885865}. Best is trial 47 with value: 0.16197297544408445.\u001b[0m\n",
      "regularization_factors, val_score: 0.161973:  40%|###############2                      | 8/20 [03:38<05:24, 27.06s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.112684\tvalid_1's multi_logloss: 0.162851\n",
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's multi_logloss: 0.109473\tvalid_1's multi_logloss: 0.16262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161973:  45%|#################1                    | 9/20 [04:03<04:48, 26.19s/it]\u001b[32m[I 2021-08-14 21:22:27,443]\u001b[0m Trial 51 finished with value: 0.16262032252870637 and parameters: {'lambda_l1': 0.022783967516625092, 'lambda_l2': 0.00010053814437389663}. Best is trial 47 with value: 0.16197297544408445.\u001b[0m\n",
      "regularization_factors, val_score: 0.161973:  45%|#################1                    | 9/20 [04:03<04:48, 26.19s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.122514\tvalid_1's multi_logloss: 0.162495\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's multi_logloss: 0.109107\tvalid_1's multi_logloss: 0.16176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161760:  50%|##################5                  | 10/20 [04:36<04:43, 28.32s/it]\u001b[32m[I 2021-08-14 21:23:00,538]\u001b[0m Trial 52 finished with value: 0.16175991388829977 and parameters: {'lambda_l1': 2.6887811144026315e-05, 'lambda_l2': 6.517576274714297}. Best is trial 52 with value: 0.16175991388829977.\u001b[0m\n",
      "regularization_factors, val_score: 0.161760:  50%|##################5                  | 10/20 [04:36<04:43, 28.32s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.133476\tvalid_1's multi_logloss: 0.163609\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's multi_logloss: 0.120825\tvalid_1's multi_logloss: 0.162503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161760:  55%|####################3                | 11/20 [05:10<04:30, 30.08s/it]\u001b[32m[I 2021-08-14 21:23:34,601]\u001b[0m Trial 53 finished with value: 0.16250299621532144 and parameters: {'lambda_l1': 7.894741906307399, 'lambda_l2': 0.015554878661108756}. Best is trial 52 with value: 0.16175991388829977.\u001b[0m\n",
      "regularization_factors, val_score: 0.161760:  55%|####################3                | 11/20 [05:10<04:30, 30.08s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.123093\tvalid_1's multi_logloss: 0.162408\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's multi_logloss: 0.110631\tvalid_1's multi_logloss: 0.161653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161653:  60%|######################2              | 12/20 [05:44<04:11, 31.40s/it]\u001b[32m[I 2021-08-14 21:24:09,032]\u001b[0m Trial 54 finished with value: 0.16165263748974665 and parameters: {'lambda_l1': 1.1252393969959254e-08, 'lambda_l2': 7.601215328081994}. Best is trial 54 with value: 0.16165263748974665.\u001b[0m\n",
      "regularization_factors, val_score: 0.161653:  60%|######################2              | 12/20 [05:44<04:11, 31.40s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.123206\tvalid_1's multi_logloss: 0.162395\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's multi_logloss: 0.106168\tvalid_1's multi_logloss: 0.161505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161505:  65%|########################             | 13/20 [06:20<03:49, 32.74s/it]\u001b[32m[I 2021-08-14 21:24:44,841]\u001b[0m Trial 55 finished with value: 0.16150475471270712 and parameters: {'lambda_l1': 1.1761578431285439e-08, 'lambda_l2': 7.745594805270928}. Best is trial 55 with value: 0.16150475471270712.\u001b[0m\n",
      "regularization_factors, val_score: 0.161505:  65%|########################             | 13/20 [06:20<03:49, 32.74s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.112825\tvalid_1's multi_logloss: 0.16291\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 0.10662\tvalid_1's multi_logloss: 0.162631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161505:  70%|#########################9           | 14/20 [06:47<03:05, 30.89s/it]\u001b[32m[I 2021-08-14 21:25:11,450]\u001b[0m Trial 56 finished with value: 0.16263083564569736 and parameters: {'lambda_l1': 1.1204993009890272e-08, 'lambda_l2': 0.13389525710975295}. Best is trial 55 with value: 0.16150475471270712.\u001b[0m\n",
      "regularization_factors, val_score: 0.161505:  70%|#########################9           | 14/20 [06:47<03:05, 30.89s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.112537\tvalid_1's multi_logloss: 0.162565\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.108917\tvalid_1's multi_logloss: 0.162285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161505:  75%|###########################7         | 15/20 [07:11<02:25, 29.00s/it]\u001b[32m[I 2021-08-14 21:25:36,081]\u001b[0m Trial 57 finished with value: 0.16228491445795248 and parameters: {'lambda_l1': 1.3279882472636319e-08, 'lambda_l2': 0.014748656630368381}. Best is trial 55 with value: 0.16150475471270712.\u001b[0m\n",
      "regularization_factors, val_score: 0.161505:  75%|###########################7         | 15/20 [07:11<02:25, 29.00s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.114056\tvalid_1's multi_logloss: 0.163102\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's multi_logloss: 0.107564\tvalid_1's multi_logloss: 0.162836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161505:  80%|#############################6       | 16/20 [07:37<01:52, 28.14s/it]\u001b[32m[I 2021-08-14 21:26:02,224]\u001b[0m Trial 58 finished with value: 0.16283646645600988 and parameters: {'lambda_l1': 5.8527966574998e-07, 'lambda_l2': 0.39257936236142876}. Best is trial 55 with value: 0.16150475471270712.\u001b[0m\n",
      "regularization_factors, val_score: 0.161505:  80%|#############################6       | 16/20 [07:38<01:52, 28.14s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.112579\tvalid_1's multi_logloss: 0.162898\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's multi_logloss: 0.108062\tvalid_1's multi_logloss: 0.162401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161505:  85%|###############################4     | 17/20 [08:02<01:21, 27.19s/it]\u001b[32m[I 2021-08-14 21:26:27,200]\u001b[0m Trial 59 finished with value: 0.16240130664612237 and parameters: {'lambda_l1': 3.117855099322706e-07, 'lambda_l2': 3.8118991602152955e-08}. Best is trial 55 with value: 0.16150475471270712.\u001b[0m\n",
      "regularization_factors, val_score: 0.161505:  85%|###############################4     | 17/20 [08:02<01:21, 27.19s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[100]\tvalid_0's multi_logloss: 0.112581\tvalid_1's multi_logloss: 0.162812\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.107407\tvalid_1's multi_logloss: 0.162619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161505:  90%|#################################3   | 18/20 [08:28<00:53, 26.70s/it]\u001b[32m[I 2021-08-14 21:26:52,784]\u001b[0m Trial 60 finished with value: 0.1626192111150443 and parameters: {'lambda_l1': 6.152976825288054e-08, 'lambda_l2': 0.01935527490295423}. Best is trial 55 with value: 0.16150475471270712.\u001b[0m\n",
      "regularization_factors, val_score: 0.161505:  90%|#################################3   | 18/20 [08:28<00:53, 26.70s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.120711\tvalid_1's multi_logloss: 0.16247\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 0.102833\tvalid_1's multi_logloss: 0.16178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161505:  95%|###################################1 | 19/20 [09:04<00:29, 29.48s/it]\u001b[32m[I 2021-08-14 21:27:28,732]\u001b[0m Trial 61 finished with value: 0.1617801645981257 and parameters: {'lambda_l1': 6.785193219784092e-06, 'lambda_l2': 4.491364373690079}. Best is trial 55 with value: 0.16150475471270712.\u001b[0m\n",
      "regularization_factors, val_score: 0.161505:  95%|###################################1 | 19/20 [09:04<00:29, 29.48s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.123779\tvalid_1's multi_logloss: 0.162433\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's multi_logloss: 0.104239\tvalid_1's multi_logloss: 0.161565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.161505: 100%|#####################################| 20/20 [09:44<00:00, 32.61s/it]\u001b[32m[I 2021-08-14 21:28:08,618]\u001b[0m Trial 62 finished with value: 0.16156498342248946 and parameters: {'lambda_l1': 2.422800518914984e-06, 'lambda_l2': 9.07441231631521}. Best is trial 55 with value: 0.16150475471270712.\u001b[0m\n",
      "regularization_factors, val_score: 0.161505: 100%|#####################################| 20/20 [09:44<00:00, 29.22s/it]\n",
      "min_data_in_leaf, val_score: 0.161505:   0%|                                                     | 0/5 [00:00<?, ?it/s]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.123692\tvalid_1's multi_logloss: 0.162378\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's multi_logloss: 0.105927\tvalid_1's multi_logloss: 0.161747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.161505:  20%|#########                                    | 1/5 [00:36<02:27, 36.88s/it]\u001b[32m[I 2021-08-14 21:28:45,516]\u001b[0m Trial 63 finished with value: 0.16174707780826686 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.16174707780826686.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.161505:  20%|#########                                    | 1/5 [00:36<02:27, 36.88s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.124335\tvalid_1's multi_logloss: 0.162596\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's multi_logloss: 0.112751\tvalid_1's multi_logloss: 0.162093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.161505:  40%|##################                           | 2/5 [01:07<01:40, 33.34s/it]\u001b[32m[I 2021-08-14 21:29:16,369]\u001b[0m Trial 64 finished with value: 0.16209264314264624 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.16174707780826686.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.161505:  40%|##################                           | 2/5 [01:07<01:40, 33.34s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.12305\tvalid_1's multi_logloss: 0.162791\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's multi_logloss: 0.11044\tvalid_1's multi_logloss: 0.162116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.161505:  60%|###########################                  | 3/5 [01:41<01:07, 33.55s/it]\u001b[32m[I 2021-08-14 21:29:50,185]\u001b[0m Trial 65 finished with value: 0.16211581911388595 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.16174707780826686.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.161505:  60%|###########################                  | 3/5 [01:41<01:07, 33.55s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.123185\tvalid_1's multi_logloss: 0.162272\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's multi_logloss: 0.107326\tvalid_1's multi_logloss: 0.16153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.161505:  80%|####################################         | 4/5 [02:14<00:33, 33.49s/it]\u001b[32m[I 2021-08-14 21:30:23,584]\u001b[0m Trial 66 finished with value: 0.1615301001450733 and parameters: {'min_child_samples': 25}. Best is trial 66 with value: 0.1615301001450733.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.161505:  80%|####################################         | 4/5 [02:14<00:33, 33.49s/it]C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 256000, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score -0.980965\n",
      "[LightGBM] [Info] Start training from score -2.012659\n",
      "[LightGBM] [Info] Start training from score -0.710460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's multi_logloss: 0.123008\tvalid_1's multi_logloss: 0.162264\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 0.106331\tvalid_1's multi_logloss: 0.161571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.161505: 100%|#############################################| 5/5 [02:51<00:00, 34.43s/it]\u001b[32m[I 2021-08-14 21:30:59,679]\u001b[0m Trial 67 finished with value: 0.16157064572427718 and parameters: {'min_child_samples': 5}. Best is trial 66 with value: 0.1615301001450733.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.161505: 100%|#############################################| 5/5 [02:51<00:00, 34.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 3, 'lambda_l1': 1.1761578431285439e-08, 'lambda_l2': 7.745594805270928, 'random_state': 42, 'n_jobs': -1, 'feature_pre_filter': False, 'bagging_freq': 1, 'num_leaves': 171, 'feature_fraction': 0.652, 'bagging_fraction': 1.0, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 10}\n",
      "  Accuracy = 0.932078125\n",
      "  Params: \n",
      "    objective: multiclass\n",
      "    metric: multi_logloss\n",
      "    num_class: 3\n",
      "    lambda_l1: 1.1761578431285439e-08\n",
      "    lambda_l2: 7.745594805270928\n",
      "    random_state: 42\n",
      "    n_jobs: -1\n",
      "    feature_pre_filter: False\n",
      "    bagging_freq: 1\n",
      "    num_leaves: 171\n",
      "    feature_fraction: 0.652\n",
      "    bagging_fraction: 1.0\n",
      "    min_child_samples: 20\n",
      "    num_iterations: 1000\n",
      "    early_stopping_round: 10\n"
     ]
    }
   ],
   "source": [
    "dtrain = lgb.Dataset(X_trn, label=y_trn)\n",
    "dval = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "model = lgb.train(params, dtrain, valid_sets=[dtrain, dval], \n",
    "                  verbose_eval=100, early_stopping_rounds=10)\n",
    "\n",
    "prediction = np.argmax(model.predict(X_val, num_iteration=model.best_iteration), \n",
    "                       axis=1)\n",
    "accuracy = accuracy_score(y_val, prediction)\n",
    "\n",
    "params = model.params\n",
    "print(\"Best params:\", params)\n",
    "print(\"  Accuracy = {}\".format(accuracy))\n",
    "print(\"  Params: \")\n",
    "for key, value in params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of Hyperparameter Tuning\n",
    "\n",
    "Best params: {'objective': 'multiclass', 'metric': 'multi_logloss', 'num_class': 3, 'lambda_l1': 1.1761578431285439e-08, 'lambda_l2': 7.745594805270928, 'random_state': 42, 'n_jobs': -1, 'feature_pre_filter': False, 'bagging_freq': 1, 'num_leaves': 171, 'feature_fraction': 0.652, 'bagging_fraction': 1.0, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 10}\n",
    "  \n",
    "Accuracy = 0.932078125\n",
    "\n",
    "Params: \n",
    "-    objective: multiclass\n",
    "-    metric: multi_logloss\n",
    "-    num_class: 3\n",
    "-    lambda_l1: 1.1761578431285439e-08\n",
    "-    lambda_l2: 7.745594805270928\n",
    "-    random_state: 42\n",
    "-    n_jobs: -1\n",
    "-    feature_pre_filter: False\n",
    "-    bagging_freq: 1\n",
    "-    num_leaves: 171\n",
    "-    feature_fraction: 0.652\n",
    "-    bagging_fraction: 1.0\n",
    "-    min_child_samples: 20\n",
    "-    num_iterations: 1000\n",
    "-    early_stopping_round: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train LightGBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for CV #1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.652, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.652\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1761578431285439e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1761578431285439e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.745594805270928, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.745594805270928\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.857789\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.756604\n",
      "[3]\tvalid_0's multi_logloss: 0.671452\n",
      "[4]\tvalid_0's multi_logloss: 0.600176\n",
      "[5]\tvalid_0's multi_logloss: 0.542217\n",
      "[6]\tvalid_0's multi_logloss: 0.502058\n",
      "[7]\tvalid_0's multi_logloss: 0.466088\n",
      "[8]\tvalid_0's multi_logloss: 0.4391\n",
      "[9]\tvalid_0's multi_logloss: 0.410658\n",
      "[10]\tvalid_0's multi_logloss: 0.382687\n",
      "[11]\tvalid_0's multi_logloss: 0.357851\n",
      "[12]\tvalid_0's multi_logloss: 0.336507\n",
      "[13]\tvalid_0's multi_logloss: 0.318223\n",
      "[14]\tvalid_0's multi_logloss: 0.302287\n",
      "[15]\tvalid_0's multi_logloss: 0.290281\n",
      "[16]\tvalid_0's multi_logloss: 0.277393\n",
      "[17]\tvalid_0's multi_logloss: 0.26636\n",
      "[18]\tvalid_0's multi_logloss: 0.25628\n",
      "[19]\tvalid_0's multi_logloss: 0.247669\n",
      "[20]\tvalid_0's multi_logloss: 0.24089\n",
      "[21]\tvalid_0's multi_logloss: 0.23345\n",
      "[22]\tvalid_0's multi_logloss: 0.227899\n",
      "[23]\tvalid_0's multi_logloss: 0.221166\n",
      "[24]\tvalid_0's multi_logloss: 0.216828\n",
      "[25]\tvalid_0's multi_logloss: 0.212042\n",
      "[26]\tvalid_0's multi_logloss: 0.208646\n",
      "[27]\tvalid_0's multi_logloss: 0.205002\n",
      "[28]\tvalid_0's multi_logloss: 0.202145\n",
      "[29]\tvalid_0's multi_logloss: 0.198538\n",
      "[30]\tvalid_0's multi_logloss: 0.19621\n",
      "[31]\tvalid_0's multi_logloss: 0.193323\n",
      "[32]\tvalid_0's multi_logloss: 0.190725\n",
      "[33]\tvalid_0's multi_logloss: 0.188005\n",
      "[34]\tvalid_0's multi_logloss: 0.185527\n",
      "[35]\tvalid_0's multi_logloss: 0.183224\n",
      "[36]\tvalid_0's multi_logloss: 0.182011\n",
      "[37]\tvalid_0's multi_logloss: 0.180957\n",
      "[38]\tvalid_0's multi_logloss: 0.179447\n",
      "[39]\tvalid_0's multi_logloss: 0.1784\n",
      "[40]\tvalid_0's multi_logloss: 0.17743\n",
      "[41]\tvalid_0's multi_logloss: 0.176228\n",
      "[42]\tvalid_0's multi_logloss: 0.175104\n",
      "[43]\tvalid_0's multi_logloss: 0.1741\n",
      "[44]\tvalid_0's multi_logloss: 0.173011\n",
      "[45]\tvalid_0's multi_logloss: 0.172468\n",
      "[46]\tvalid_0's multi_logloss: 0.171838\n",
      "[47]\tvalid_0's multi_logloss: 0.171259\n",
      "[48]\tvalid_0's multi_logloss: 0.170643\n",
      "[49]\tvalid_0's multi_logloss: 0.169843\n",
      "[50]\tvalid_0's multi_logloss: 0.169325\n",
      "[51]\tvalid_0's multi_logloss: 0.168673\n",
      "[52]\tvalid_0's multi_logloss: 0.168256\n",
      "[53]\tvalid_0's multi_logloss: 0.16765\n",
      "[54]\tvalid_0's multi_logloss: 0.167508\n",
      "[55]\tvalid_0's multi_logloss: 0.167253\n",
      "[56]\tvalid_0's multi_logloss: 0.166905\n",
      "[57]\tvalid_0's multi_logloss: 0.166583\n",
      "[58]\tvalid_0's multi_logloss: 0.166255\n",
      "[59]\tvalid_0's multi_logloss: 0.165893\n",
      "[60]\tvalid_0's multi_logloss: 0.165495\n",
      "[61]\tvalid_0's multi_logloss: 0.165102\n",
      "[62]\tvalid_0's multi_logloss: 0.164926\n",
      "[63]\tvalid_0's multi_logloss: 0.164572\n",
      "[64]\tvalid_0's multi_logloss: 0.16421\n",
      "[65]\tvalid_0's multi_logloss: 0.163985\n",
      "[66]\tvalid_0's multi_logloss: 0.163659\n",
      "[67]\tvalid_0's multi_logloss: 0.163357\n",
      "[68]\tvalid_0's multi_logloss: 0.163126\n",
      "[69]\tvalid_0's multi_logloss: 0.162849\n",
      "[70]\tvalid_0's multi_logloss: 0.162578\n",
      "[71]\tvalid_0's multi_logloss: 0.162452\n",
      "[72]\tvalid_0's multi_logloss: 0.162301\n",
      "[73]\tvalid_0's multi_logloss: 0.162173\n",
      "[74]\tvalid_0's multi_logloss: 0.162062\n",
      "[75]\tvalid_0's multi_logloss: 0.161968\n",
      "[76]\tvalid_0's multi_logloss: 0.161781\n",
      "[77]\tvalid_0's multi_logloss: 0.161661\n",
      "[78]\tvalid_0's multi_logloss: 0.161598\n",
      "[79]\tvalid_0's multi_logloss: 0.161475\n",
      "[80]\tvalid_0's multi_logloss: 0.16138\n",
      "[81]\tvalid_0's multi_logloss: 0.161268\n",
      "[82]\tvalid_0's multi_logloss: 0.161126\n",
      "[83]\tvalid_0's multi_logloss: 0.161012\n",
      "[84]\tvalid_0's multi_logloss: 0.160895\n",
      "[85]\tvalid_0's multi_logloss: 0.160813\n",
      "[86]\tvalid_0's multi_logloss: 0.160728\n",
      "[87]\tvalid_0's multi_logloss: 0.160659\n",
      "[88]\tvalid_0's multi_logloss: 0.160584\n",
      "[89]\tvalid_0's multi_logloss: 0.160577\n",
      "[90]\tvalid_0's multi_logloss: 0.160559\n",
      "[91]\tvalid_0's multi_logloss: 0.160534\n",
      "[92]\tvalid_0's multi_logloss: 0.160468\n",
      "[93]\tvalid_0's multi_logloss: 0.160425\n",
      "[94]\tvalid_0's multi_logloss: 0.16034\n",
      "[95]\tvalid_0's multi_logloss: 0.160283\n",
      "[96]\tvalid_0's multi_logloss: 0.160243\n",
      "[97]\tvalid_0's multi_logloss: 0.160144\n",
      "[98]\tvalid_0's multi_logloss: 0.160118\n",
      "[99]\tvalid_0's multi_logloss: 0.160098\n",
      "[100]\tvalid_0's multi_logloss: 0.16008\n",
      "[101]\tvalid_0's multi_logloss: 0.160051\n",
      "[102]\tvalid_0's multi_logloss: 0.160045\n",
      "[103]\tvalid_0's multi_logloss: 0.160016\n",
      "[104]\tvalid_0's multi_logloss: 0.159962\n",
      "[105]\tvalid_0's multi_logloss: 0.159936\n",
      "[106]\tvalid_0's multi_logloss: 0.159923\n",
      "[107]\tvalid_0's multi_logloss: 0.159911\n",
      "[108]\tvalid_0's multi_logloss: 0.15987\n",
      "[109]\tvalid_0's multi_logloss: 0.159851\n",
      "[110]\tvalid_0's multi_logloss: 0.159858\n",
      "[111]\tvalid_0's multi_logloss: 0.15986\n",
      "[112]\tvalid_0's multi_logloss: 0.159832\n",
      "[113]\tvalid_0's multi_logloss: 0.159844\n",
      "[114]\tvalid_0's multi_logloss: 0.159842\n",
      "[115]\tvalid_0's multi_logloss: 0.159833\n",
      "[116]\tvalid_0's multi_logloss: 0.159818\n",
      "[117]\tvalid_0's multi_logloss: 0.159781\n",
      "[118]\tvalid_0's multi_logloss: 0.159788\n",
      "[119]\tvalid_0's multi_logloss: 0.159743\n",
      "[120]\tvalid_0's multi_logloss: 0.159739\n",
      "[121]\tvalid_0's multi_logloss: 0.159699\n",
      "[122]\tvalid_0's multi_logloss: 0.15967\n",
      "[123]\tvalid_0's multi_logloss: 0.159639\n",
      "[124]\tvalid_0's multi_logloss: 0.159619\n",
      "[125]\tvalid_0's multi_logloss: 0.159611\n",
      "[126]\tvalid_0's multi_logloss: 0.159602\n",
      "[127]\tvalid_0's multi_logloss: 0.159603\n",
      "[128]\tvalid_0's multi_logloss: 0.159611\n",
      "[129]\tvalid_0's multi_logloss: 0.159615\n",
      "[130]\tvalid_0's multi_logloss: 0.159645\n",
      "[131]\tvalid_0's multi_logloss: 0.159607\n",
      "[132]\tvalid_0's multi_logloss: 0.159598\n",
      "[133]\tvalid_0's multi_logloss: 0.159581\n",
      "[134]\tvalid_0's multi_logloss: 0.159604\n",
      "[135]\tvalid_0's multi_logloss: 0.159598\n",
      "[136]\tvalid_0's multi_logloss: 0.15959\n",
      "[137]\tvalid_0's multi_logloss: 0.159601\n",
      "[138]\tvalid_0's multi_logloss: 0.159574\n",
      "[139]\tvalid_0's multi_logloss: 0.159571\n",
      "[140]\tvalid_0's multi_logloss: 0.159578\n",
      "[141]\tvalid_0's multi_logloss: 0.159591\n",
      "[142]\tvalid_0's multi_logloss: 0.159609\n",
      "[143]\tvalid_0's multi_logloss: 0.159597\n",
      "[144]\tvalid_0's multi_logloss: 0.159589\n",
      "[145]\tvalid_0's multi_logloss: 0.159595\n",
      "[146]\tvalid_0's multi_logloss: 0.159603\n",
      "[147]\tvalid_0's multi_logloss: 0.159611\n",
      "[148]\tvalid_0's multi_logloss: 0.159592\n",
      "[149]\tvalid_0's multi_logloss: 0.159578\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's multi_logloss: 0.159571\n",
      "training model for CV #2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.652, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.652\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1761578431285439e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1761578431285439e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.745594805270928, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.745594805270928\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.858461\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.757518\n",
      "[3]\tvalid_0's multi_logloss: 0.672438\n",
      "[4]\tvalid_0's multi_logloss: 0.601356\n",
      "[5]\tvalid_0's multi_logloss: 0.543062\n",
      "[6]\tvalid_0's multi_logloss: 0.502957\n",
      "[7]\tvalid_0's multi_logloss: 0.466869\n",
      "[8]\tvalid_0's multi_logloss: 0.439898\n",
      "[9]\tvalid_0's multi_logloss: 0.411584\n",
      "[10]\tvalid_0's multi_logloss: 0.383652\n",
      "[11]\tvalid_0's multi_logloss: 0.358885\n",
      "[12]\tvalid_0's multi_logloss: 0.337614\n",
      "[13]\tvalid_0's multi_logloss: 0.319452\n",
      "[14]\tvalid_0's multi_logloss: 0.30364\n",
      "[15]\tvalid_0's multi_logloss: 0.291624\n",
      "[16]\tvalid_0's multi_logloss: 0.279015\n",
      "[17]\tvalid_0's multi_logloss: 0.267955\n",
      "[18]\tvalid_0's multi_logloss: 0.257875\n",
      "[19]\tvalid_0's multi_logloss: 0.24925\n",
      "[20]\tvalid_0's multi_logloss: 0.242439\n",
      "[21]\tvalid_0's multi_logloss: 0.23491\n",
      "[22]\tvalid_0's multi_logloss: 0.229369\n",
      "[23]\tvalid_0's multi_logloss: 0.222665\n",
      "[24]\tvalid_0's multi_logloss: 0.218293\n",
      "[25]\tvalid_0's multi_logloss: 0.213515\n",
      "[26]\tvalid_0's multi_logloss: 0.210079\n",
      "[27]\tvalid_0's multi_logloss: 0.206436\n",
      "[28]\tvalid_0's multi_logloss: 0.203486\n",
      "[29]\tvalid_0's multi_logloss: 0.199824\n",
      "[30]\tvalid_0's multi_logloss: 0.197475\n",
      "[31]\tvalid_0's multi_logloss: 0.194522\n",
      "[32]\tvalid_0's multi_logloss: 0.191928\n",
      "[33]\tvalid_0's multi_logloss: 0.189132\n",
      "[34]\tvalid_0's multi_logloss: 0.186597\n",
      "[35]\tvalid_0's multi_logloss: 0.184315\n",
      "[36]\tvalid_0's multi_logloss: 0.183062\n",
      "[37]\tvalid_0's multi_logloss: 0.181991\n",
      "[38]\tvalid_0's multi_logloss: 0.180456\n",
      "[39]\tvalid_0's multi_logloss: 0.179341\n",
      "[40]\tvalid_0's multi_logloss: 0.178377\n",
      "[41]\tvalid_0's multi_logloss: 0.177199\n",
      "[42]\tvalid_0's multi_logloss: 0.176034\n",
      "[43]\tvalid_0's multi_logloss: 0.17506\n",
      "[44]\tvalid_0's multi_logloss: 0.173995\n",
      "[45]\tvalid_0's multi_logloss: 0.173407\n",
      "[46]\tvalid_0's multi_logloss: 0.172802\n",
      "[47]\tvalid_0's multi_logloss: 0.172169\n",
      "[48]\tvalid_0's multi_logloss: 0.171598\n",
      "[49]\tvalid_0's multi_logloss: 0.170783\n",
      "[50]\tvalid_0's multi_logloss: 0.170215\n",
      "[51]\tvalid_0's multi_logloss: 0.169541\n",
      "[52]\tvalid_0's multi_logloss: 0.169073\n",
      "[53]\tvalid_0's multi_logloss: 0.168463\n",
      "[54]\tvalid_0's multi_logloss: 0.168321\n",
      "[55]\tvalid_0's multi_logloss: 0.168049\n",
      "[56]\tvalid_0's multi_logloss: 0.167721\n",
      "[57]\tvalid_0's multi_logloss: 0.167436\n",
      "[58]\tvalid_0's multi_logloss: 0.167115\n",
      "[59]\tvalid_0's multi_logloss: 0.166781\n",
      "[60]\tvalid_0's multi_logloss: 0.166404\n",
      "[61]\tvalid_0's multi_logloss: 0.166029\n",
      "[62]\tvalid_0's multi_logloss: 0.165879\n",
      "[63]\tvalid_0's multi_logloss: 0.165529\n",
      "[64]\tvalid_0's multi_logloss: 0.165195\n",
      "[65]\tvalid_0's multi_logloss: 0.164951\n",
      "[66]\tvalid_0's multi_logloss: 0.164688\n",
      "[67]\tvalid_0's multi_logloss: 0.164421\n",
      "[68]\tvalid_0's multi_logloss: 0.164165\n",
      "[69]\tvalid_0's multi_logloss: 0.163916\n",
      "[70]\tvalid_0's multi_logloss: 0.163735\n",
      "[71]\tvalid_0's multi_logloss: 0.163607\n",
      "[72]\tvalid_0's multi_logloss: 0.163488\n",
      "[73]\tvalid_0's multi_logloss: 0.163366\n",
      "[74]\tvalid_0's multi_logloss: 0.163245\n",
      "[75]\tvalid_0's multi_logloss: 0.163174\n",
      "[76]\tvalid_0's multi_logloss: 0.163027\n",
      "[77]\tvalid_0's multi_logloss: 0.162914\n",
      "[78]\tvalid_0's multi_logloss: 0.162773\n",
      "[79]\tvalid_0's multi_logloss: 0.16262\n",
      "[80]\tvalid_0's multi_logloss: 0.162573\n",
      "[81]\tvalid_0's multi_logloss: 0.162434\n",
      "[82]\tvalid_0's multi_logloss: 0.162296\n",
      "[83]\tvalid_0's multi_logloss: 0.162173\n",
      "[84]\tvalid_0's multi_logloss: 0.162076\n",
      "[85]\tvalid_0's multi_logloss: 0.16198\n",
      "[86]\tvalid_0's multi_logloss: 0.161914\n",
      "[87]\tvalid_0's multi_logloss: 0.161876\n",
      "[88]\tvalid_0's multi_logloss: 0.1618\n",
      "[89]\tvalid_0's multi_logloss: 0.161726\n",
      "[90]\tvalid_0's multi_logloss: 0.16166\n",
      "[91]\tvalid_0's multi_logloss: 0.16163\n",
      "[92]\tvalid_0's multi_logloss: 0.161572\n",
      "[93]\tvalid_0's multi_logloss: 0.161489\n",
      "[94]\tvalid_0's multi_logloss: 0.161429\n",
      "[95]\tvalid_0's multi_logloss: 0.161403\n",
      "[96]\tvalid_0's multi_logloss: 0.161378\n",
      "[97]\tvalid_0's multi_logloss: 0.161308\n",
      "[98]\tvalid_0's multi_logloss: 0.161269\n",
      "[99]\tvalid_0's multi_logloss: 0.161231\n",
      "[100]\tvalid_0's multi_logloss: 0.161193\n",
      "[101]\tvalid_0's multi_logloss: 0.161175\n",
      "[102]\tvalid_0's multi_logloss: 0.16113\n",
      "[103]\tvalid_0's multi_logloss: 0.161087\n",
      "[104]\tvalid_0's multi_logloss: 0.161047\n",
      "[105]\tvalid_0's multi_logloss: 0.160999\n",
      "[106]\tvalid_0's multi_logloss: 0.160981\n",
      "[107]\tvalid_0's multi_logloss: 0.160954\n",
      "[108]\tvalid_0's multi_logloss: 0.160921\n",
      "[109]\tvalid_0's multi_logloss: 0.160878\n",
      "[110]\tvalid_0's multi_logloss: 0.16087\n",
      "[111]\tvalid_0's multi_logloss: 0.16086\n",
      "[112]\tvalid_0's multi_logloss: 0.160827\n",
      "[113]\tvalid_0's multi_logloss: 0.160827\n",
      "[114]\tvalid_0's multi_logloss: 0.16084\n",
      "[115]\tvalid_0's multi_logloss: 0.160818\n",
      "[116]\tvalid_0's multi_logloss: 0.160809\n",
      "[117]\tvalid_0's multi_logloss: 0.160761\n",
      "[118]\tvalid_0's multi_logloss: 0.160726\n",
      "[119]\tvalid_0's multi_logloss: 0.160707\n",
      "[120]\tvalid_0's multi_logloss: 0.160722\n",
      "[121]\tvalid_0's multi_logloss: 0.160708\n",
      "[122]\tvalid_0's multi_logloss: 0.160697\n",
      "[123]\tvalid_0's multi_logloss: 0.160646\n",
      "[124]\tvalid_0's multi_logloss: 0.160601\n",
      "[125]\tvalid_0's multi_logloss: 0.160589\n",
      "[126]\tvalid_0's multi_logloss: 0.160593\n",
      "[127]\tvalid_0's multi_logloss: 0.160591\n",
      "[128]\tvalid_0's multi_logloss: 0.160573\n",
      "[129]\tvalid_0's multi_logloss: 0.160585\n",
      "[130]\tvalid_0's multi_logloss: 0.160566\n",
      "[131]\tvalid_0's multi_logloss: 0.160534\n",
      "[132]\tvalid_0's multi_logloss: 0.160483\n",
      "[133]\tvalid_0's multi_logloss: 0.160487\n",
      "[134]\tvalid_0's multi_logloss: 0.160492\n",
      "[135]\tvalid_0's multi_logloss: 0.160483\n",
      "[136]\tvalid_0's multi_logloss: 0.160478\n",
      "[137]\tvalid_0's multi_logloss: 0.160471\n",
      "[138]\tvalid_0's multi_logloss: 0.160455\n",
      "[139]\tvalid_0's multi_logloss: 0.160444\n",
      "[140]\tvalid_0's multi_logloss: 0.160423\n",
      "[141]\tvalid_0's multi_logloss: 0.16039\n",
      "[142]\tvalid_0's multi_logloss: 0.160364\n",
      "[143]\tvalid_0's multi_logloss: 0.160357\n",
      "[144]\tvalid_0's multi_logloss: 0.160347\n",
      "[145]\tvalid_0's multi_logloss: 0.16032\n",
      "[146]\tvalid_0's multi_logloss: 0.160316\n",
      "[147]\tvalid_0's multi_logloss: 0.160311\n",
      "[148]\tvalid_0's multi_logloss: 0.160299\n",
      "[149]\tvalid_0's multi_logloss: 0.160291\n",
      "[150]\tvalid_0's multi_logloss: 0.160269\n",
      "[151]\tvalid_0's multi_logloss: 0.160277\n",
      "[152]\tvalid_0's multi_logloss: 0.160244\n",
      "[153]\tvalid_0's multi_logloss: 0.160242\n",
      "[154]\tvalid_0's multi_logloss: 0.160236\n",
      "[155]\tvalid_0's multi_logloss: 0.160234\n",
      "[156]\tvalid_0's multi_logloss: 0.160226\n",
      "[157]\tvalid_0's multi_logloss: 0.160235\n",
      "[158]\tvalid_0's multi_logloss: 0.160224\n",
      "[159]\tvalid_0's multi_logloss: 0.160201\n",
      "[160]\tvalid_0's multi_logloss: 0.160209\n",
      "[161]\tvalid_0's multi_logloss: 0.160218\n",
      "[162]\tvalid_0's multi_logloss: 0.160212\n",
      "[163]\tvalid_0's multi_logloss: 0.160195\n",
      "[164]\tvalid_0's multi_logloss: 0.160185\n",
      "[165]\tvalid_0's multi_logloss: 0.160198\n",
      "[166]\tvalid_0's multi_logloss: 0.160206\n",
      "[167]\tvalid_0's multi_logloss: 0.160221\n",
      "[168]\tvalid_0's multi_logloss: 0.1602\n",
      "[169]\tvalid_0's multi_logloss: 0.160198\n",
      "[170]\tvalid_0's multi_logloss: 0.16021\n",
      "[171]\tvalid_0's multi_logloss: 0.160195\n",
      "[172]\tvalid_0's multi_logloss: 0.160171\n",
      "[173]\tvalid_0's multi_logloss: 0.160189\n",
      "[174]\tvalid_0's multi_logloss: 0.1602\n",
      "[175]\tvalid_0's multi_logloss: 0.160194\n",
      "[176]\tvalid_0's multi_logloss: 0.16018\n",
      "[177]\tvalid_0's multi_logloss: 0.160168\n",
      "[178]\tvalid_0's multi_logloss: 0.160167\n",
      "[179]\tvalid_0's multi_logloss: 0.160184\n",
      "[180]\tvalid_0's multi_logloss: 0.160192\n",
      "[181]\tvalid_0's multi_logloss: 0.160207\n",
      "[182]\tvalid_0's multi_logloss: 0.160198\n",
      "[183]\tvalid_0's multi_logloss: 0.160195\n",
      "[184]\tvalid_0's multi_logloss: 0.160194\n",
      "[185]\tvalid_0's multi_logloss: 0.160203\n",
      "[186]\tvalid_0's multi_logloss: 0.160204\n",
      "[187]\tvalid_0's multi_logloss: 0.160211\n",
      "[188]\tvalid_0's multi_logloss: 0.160217\n",
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's multi_logloss: 0.160167\n",
      "training model for CV #3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.652, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.652\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1761578431285439e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1761578431285439e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.745594805270928, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.745594805270928\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.857903\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.756863\n",
      "[3]\tvalid_0's multi_logloss: 0.672098\n",
      "[4]\tvalid_0's multi_logloss: 0.600923\n",
      "[5]\tvalid_0's multi_logloss: 0.542889\n",
      "[6]\tvalid_0's multi_logloss: 0.502714\n",
      "[7]\tvalid_0's multi_logloss: 0.466897\n",
      "[8]\tvalid_0's multi_logloss: 0.439797\n",
      "[9]\tvalid_0's multi_logloss: 0.411857\n",
      "[10]\tvalid_0's multi_logloss: 0.383995\n",
      "[11]\tvalid_0's multi_logloss: 0.359209\n",
      "[12]\tvalid_0's multi_logloss: 0.337862\n",
      "[13]\tvalid_0's multi_logloss: 0.319843\n",
      "[14]\tvalid_0's multi_logloss: 0.303934\n",
      "[15]\tvalid_0's multi_logloss: 0.292149\n",
      "[16]\tvalid_0's multi_logloss: 0.279549\n",
      "[17]\tvalid_0's multi_logloss: 0.268514\n",
      "[18]\tvalid_0's multi_logloss: 0.258493\n",
      "[19]\tvalid_0's multi_logloss: 0.249877\n",
      "[20]\tvalid_0's multi_logloss: 0.243151\n",
      "[21]\tvalid_0's multi_logloss: 0.235694\n",
      "[22]\tvalid_0's multi_logloss: 0.230098\n",
      "[23]\tvalid_0's multi_logloss: 0.223307\n",
      "[24]\tvalid_0's multi_logloss: 0.218976\n",
      "[25]\tvalid_0's multi_logloss: 0.214265\n",
      "[26]\tvalid_0's multi_logloss: 0.210766\n",
      "[27]\tvalid_0's multi_logloss: 0.207149\n",
      "[28]\tvalid_0's multi_logloss: 0.204247\n",
      "[29]\tvalid_0's multi_logloss: 0.200557\n",
      "[30]\tvalid_0's multi_logloss: 0.19821\n",
      "[31]\tvalid_0's multi_logloss: 0.195321\n",
      "[32]\tvalid_0's multi_logloss: 0.192791\n",
      "[33]\tvalid_0's multi_logloss: 0.190068\n",
      "[34]\tvalid_0's multi_logloss: 0.187501\n",
      "[35]\tvalid_0's multi_logloss: 0.185147\n",
      "[36]\tvalid_0's multi_logloss: 0.183932\n",
      "[37]\tvalid_0's multi_logloss: 0.182829\n",
      "[38]\tvalid_0's multi_logloss: 0.181343\n",
      "[39]\tvalid_0's multi_logloss: 0.180201\n",
      "[40]\tvalid_0's multi_logloss: 0.179181\n",
      "[41]\tvalid_0's multi_logloss: 0.178015\n",
      "[42]\tvalid_0's multi_logloss: 0.176888\n",
      "[43]\tvalid_0's multi_logloss: 0.175921\n",
      "[44]\tvalid_0's multi_logloss: 0.174837\n",
      "[45]\tvalid_0's multi_logloss: 0.174245\n",
      "[46]\tvalid_0's multi_logloss: 0.173608\n",
      "[47]\tvalid_0's multi_logloss: 0.172949\n",
      "[48]\tvalid_0's multi_logloss: 0.172401\n",
      "[49]\tvalid_0's multi_logloss: 0.171637\n",
      "[50]\tvalid_0's multi_logloss: 0.171037\n",
      "[51]\tvalid_0's multi_logloss: 0.170268\n",
      "[52]\tvalid_0's multi_logloss: 0.16981\n",
      "[53]\tvalid_0's multi_logloss: 0.1692\n",
      "[54]\tvalid_0's multi_logloss: 0.169039\n",
      "[55]\tvalid_0's multi_logloss: 0.168766\n",
      "[56]\tvalid_0's multi_logloss: 0.168423\n",
      "[57]\tvalid_0's multi_logloss: 0.168096\n",
      "[58]\tvalid_0's multi_logloss: 0.167821\n",
      "[59]\tvalid_0's multi_logloss: 0.167494\n",
      "[60]\tvalid_0's multi_logloss: 0.167177\n",
      "[61]\tvalid_0's multi_logloss: 0.166772\n",
      "[62]\tvalid_0's multi_logloss: 0.166626\n",
      "[63]\tvalid_0's multi_logloss: 0.166245\n",
      "[64]\tvalid_0's multi_logloss: 0.165934\n",
      "[65]\tvalid_0's multi_logloss: 0.16568\n",
      "[66]\tvalid_0's multi_logloss: 0.16535\n",
      "[67]\tvalid_0's multi_logloss: 0.165014\n",
      "[68]\tvalid_0's multi_logloss: 0.16473\n",
      "[69]\tvalid_0's multi_logloss: 0.164505\n",
      "[70]\tvalid_0's multi_logloss: 0.164298\n",
      "[71]\tvalid_0's multi_logloss: 0.164139\n",
      "[72]\tvalid_0's multi_logloss: 0.164009\n",
      "[73]\tvalid_0's multi_logloss: 0.16383\n",
      "[74]\tvalid_0's multi_logloss: 0.163725\n",
      "[75]\tvalid_0's multi_logloss: 0.163584\n",
      "[76]\tvalid_0's multi_logloss: 0.163421\n",
      "[77]\tvalid_0's multi_logloss: 0.163277\n",
      "[78]\tvalid_0's multi_logloss: 0.163137\n",
      "[79]\tvalid_0's multi_logloss: 0.162978\n",
      "[80]\tvalid_0's multi_logloss: 0.162921\n",
      "[81]\tvalid_0's multi_logloss: 0.162818\n",
      "[82]\tvalid_0's multi_logloss: 0.162656\n",
      "[83]\tvalid_0's multi_logloss: 0.162567\n",
      "[84]\tvalid_0's multi_logloss: 0.16246\n",
      "[85]\tvalid_0's multi_logloss: 0.162355\n",
      "[86]\tvalid_0's multi_logloss: 0.162273\n",
      "[87]\tvalid_0's multi_logloss: 0.1622\n",
      "[88]\tvalid_0's multi_logloss: 0.162099\n",
      "[89]\tvalid_0's multi_logloss: 0.162035\n",
      "[90]\tvalid_0's multi_logloss: 0.161975\n",
      "[91]\tvalid_0's multi_logloss: 0.161948\n",
      "[92]\tvalid_0's multi_logloss: 0.161901\n",
      "[93]\tvalid_0's multi_logloss: 0.161828\n",
      "[94]\tvalid_0's multi_logloss: 0.161723\n",
      "[95]\tvalid_0's multi_logloss: 0.161706\n",
      "[96]\tvalid_0's multi_logloss: 0.161678\n",
      "[97]\tvalid_0's multi_logloss: 0.16159\n",
      "[98]\tvalid_0's multi_logloss: 0.161542\n",
      "[99]\tvalid_0's multi_logloss: 0.161494\n",
      "[100]\tvalid_0's multi_logloss: 0.16143\n",
      "[101]\tvalid_0's multi_logloss: 0.1614\n",
      "[102]\tvalid_0's multi_logloss: 0.16136\n",
      "[103]\tvalid_0's multi_logloss: 0.161319\n",
      "[104]\tvalid_0's multi_logloss: 0.161267\n",
      "[105]\tvalid_0's multi_logloss: 0.161238\n",
      "[106]\tvalid_0's multi_logloss: 0.161232\n",
      "[107]\tvalid_0's multi_logloss: 0.161205\n",
      "[108]\tvalid_0's multi_logloss: 0.16115\n",
      "[109]\tvalid_0's multi_logloss: 0.161137\n",
      "[110]\tvalid_0's multi_logloss: 0.161151\n",
      "[111]\tvalid_0's multi_logloss: 0.161145\n",
      "[112]\tvalid_0's multi_logloss: 0.161118\n",
      "[113]\tvalid_0's multi_logloss: 0.161096\n",
      "[114]\tvalid_0's multi_logloss: 0.161115\n",
      "[115]\tvalid_0's multi_logloss: 0.16112\n",
      "[116]\tvalid_0's multi_logloss: 0.161114\n",
      "[117]\tvalid_0's multi_logloss: 0.161095\n",
      "[118]\tvalid_0's multi_logloss: 0.161081\n",
      "[119]\tvalid_0's multi_logloss: 0.161068\n",
      "[120]\tvalid_0's multi_logloss: 0.161073\n",
      "[121]\tvalid_0's multi_logloss: 0.161032\n",
      "[122]\tvalid_0's multi_logloss: 0.161023\n",
      "[123]\tvalid_0's multi_logloss: 0.160999\n",
      "[124]\tvalid_0's multi_logloss: 0.160978\n",
      "[125]\tvalid_0's multi_logloss: 0.160971\n",
      "[126]\tvalid_0's multi_logloss: 0.160964\n",
      "[127]\tvalid_0's multi_logloss: 0.160955\n",
      "[128]\tvalid_0's multi_logloss: 0.160941\n",
      "[129]\tvalid_0's multi_logloss: 0.160959\n",
      "[130]\tvalid_0's multi_logloss: 0.160948\n",
      "[131]\tvalid_0's multi_logloss: 0.16094\n",
      "[132]\tvalid_0's multi_logloss: 0.160944\n",
      "[133]\tvalid_0's multi_logloss: 0.160955\n",
      "[134]\tvalid_0's multi_logloss: 0.16094\n",
      "[135]\tvalid_0's multi_logloss: 0.160919\n",
      "[136]\tvalid_0's multi_logloss: 0.160906\n",
      "[137]\tvalid_0's multi_logloss: 0.160906\n",
      "[138]\tvalid_0's multi_logloss: 0.160885\n",
      "[139]\tvalid_0's multi_logloss: 0.160861\n",
      "[140]\tvalid_0's multi_logloss: 0.160867\n",
      "[141]\tvalid_0's multi_logloss: 0.160865\n",
      "[142]\tvalid_0's multi_logloss: 0.160859\n",
      "[143]\tvalid_0's multi_logloss: 0.16086\n",
      "[144]\tvalid_0's multi_logloss: 0.160843\n",
      "[145]\tvalid_0's multi_logloss: 0.160839\n",
      "[146]\tvalid_0's multi_logloss: 0.160849\n",
      "[147]\tvalid_0's multi_logloss: 0.160855\n",
      "[148]\tvalid_0's multi_logloss: 0.160864\n",
      "[149]\tvalid_0's multi_logloss: 0.16086\n",
      "[150]\tvalid_0's multi_logloss: 0.160826\n",
      "[151]\tvalid_0's multi_logloss: 0.160853\n",
      "[152]\tvalid_0's multi_logloss: 0.160855\n",
      "[153]\tvalid_0's multi_logloss: 0.160844\n",
      "[154]\tvalid_0's multi_logloss: 0.160859\n",
      "[155]\tvalid_0's multi_logloss: 0.160852\n",
      "[156]\tvalid_0's multi_logloss: 0.160858\n",
      "[157]\tvalid_0's multi_logloss: 0.16087\n",
      "[158]\tvalid_0's multi_logloss: 0.160844\n",
      "[159]\tvalid_0's multi_logloss: 0.160883\n",
      "[160]\tvalid_0's multi_logloss: 0.160874\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's multi_logloss: 0.160826\n",
      "training model for CV #4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.652, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.652\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1761578431285439e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1761578431285439e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.745594805270928, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.745594805270928\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.858326\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.757503\n",
      "[3]\tvalid_0's multi_logloss: 0.672382\n",
      "[4]\tvalid_0's multi_logloss: 0.601183\n",
      "[5]\tvalid_0's multi_logloss: 0.543036\n",
      "[6]\tvalid_0's multi_logloss: 0.503018\n",
      "[7]\tvalid_0's multi_logloss: 0.467026\n",
      "[8]\tvalid_0's multi_logloss: 0.44014\n",
      "[9]\tvalid_0's multi_logloss: 0.411642\n",
      "[10]\tvalid_0's multi_logloss: 0.383654\n",
      "[11]\tvalid_0's multi_logloss: 0.358961\n",
      "[12]\tvalid_0's multi_logloss: 0.33778\n",
      "[13]\tvalid_0's multi_logloss: 0.319565\n",
      "[14]\tvalid_0's multi_logloss: 0.303766\n",
      "[15]\tvalid_0's multi_logloss: 0.292016\n",
      "[16]\tvalid_0's multi_logloss: 0.279412\n",
      "[17]\tvalid_0's multi_logloss: 0.268355\n",
      "[18]\tvalid_0's multi_logloss: 0.258377\n",
      "[19]\tvalid_0's multi_logloss: 0.249762\n",
      "[20]\tvalid_0's multi_logloss: 0.242884\n",
      "[21]\tvalid_0's multi_logloss: 0.23546\n",
      "[22]\tvalid_0's multi_logloss: 0.229899\n",
      "[23]\tvalid_0's multi_logloss: 0.223309\n",
      "[24]\tvalid_0's multi_logloss: 0.218911\n",
      "[25]\tvalid_0's multi_logloss: 0.21421\n",
      "[26]\tvalid_0's multi_logloss: 0.210903\n",
      "[27]\tvalid_0's multi_logloss: 0.207217\n",
      "[28]\tvalid_0's multi_logloss: 0.204337\n",
      "[29]\tvalid_0's multi_logloss: 0.200756\n",
      "[30]\tvalid_0's multi_logloss: 0.198377\n",
      "[31]\tvalid_0's multi_logloss: 0.19541\n",
      "[32]\tvalid_0's multi_logloss: 0.192812\n",
      "[33]\tvalid_0's multi_logloss: 0.190071\n",
      "[34]\tvalid_0's multi_logloss: 0.187555\n",
      "[35]\tvalid_0's multi_logloss: 0.185256\n",
      "[36]\tvalid_0's multi_logloss: 0.184031\n",
      "[37]\tvalid_0's multi_logloss: 0.182961\n",
      "[38]\tvalid_0's multi_logloss: 0.181438\n",
      "[39]\tvalid_0's multi_logloss: 0.180314\n",
      "[40]\tvalid_0's multi_logloss: 0.179345\n",
      "[41]\tvalid_0's multi_logloss: 0.178138\n",
      "[42]\tvalid_0's multi_logloss: 0.176989\n",
      "[43]\tvalid_0's multi_logloss: 0.175963\n",
      "[44]\tvalid_0's multi_logloss: 0.174904\n",
      "[45]\tvalid_0's multi_logloss: 0.174286\n",
      "[46]\tvalid_0's multi_logloss: 0.173653\n",
      "[47]\tvalid_0's multi_logloss: 0.173045\n",
      "[48]\tvalid_0's multi_logloss: 0.172468\n",
      "[49]\tvalid_0's multi_logloss: 0.171708\n",
      "[50]\tvalid_0's multi_logloss: 0.171184\n",
      "[51]\tvalid_0's multi_logloss: 0.170481\n",
      "[52]\tvalid_0's multi_logloss: 0.170063\n",
      "[53]\tvalid_0's multi_logloss: 0.169464\n",
      "[54]\tvalid_0's multi_logloss: 0.169298\n",
      "[55]\tvalid_0's multi_logloss: 0.169044\n",
      "[56]\tvalid_0's multi_logloss: 0.168718\n",
      "[57]\tvalid_0's multi_logloss: 0.168393\n",
      "[58]\tvalid_0's multi_logloss: 0.168052\n",
      "[59]\tvalid_0's multi_logloss: 0.167687\n",
      "[60]\tvalid_0's multi_logloss: 0.167365\n",
      "[61]\tvalid_0's multi_logloss: 0.166957\n",
      "[62]\tvalid_0's multi_logloss: 0.166809\n",
      "[63]\tvalid_0's multi_logloss: 0.166448\n",
      "[64]\tvalid_0's multi_logloss: 0.166093\n",
      "[65]\tvalid_0's multi_logloss: 0.165823\n",
      "[66]\tvalid_0's multi_logloss: 0.165567\n",
      "[67]\tvalid_0's multi_logloss: 0.165264\n",
      "[68]\tvalid_0's multi_logloss: 0.164999\n",
      "[69]\tvalid_0's multi_logloss: 0.164756\n",
      "[70]\tvalid_0's multi_logloss: 0.16453\n",
      "[71]\tvalid_0's multi_logloss: 0.164384\n",
      "[72]\tvalid_0's multi_logloss: 0.16424\n",
      "[73]\tvalid_0's multi_logloss: 0.164099\n",
      "[74]\tvalid_0's multi_logloss: 0.163996\n",
      "[75]\tvalid_0's multi_logloss: 0.163871\n",
      "[76]\tvalid_0's multi_logloss: 0.163649\n",
      "[77]\tvalid_0's multi_logloss: 0.163521\n",
      "[78]\tvalid_0's multi_logloss: 0.16344\n",
      "[79]\tvalid_0's multi_logloss: 0.163295\n",
      "[80]\tvalid_0's multi_logloss: 0.163257\n",
      "[81]\tvalid_0's multi_logloss: 0.163146\n",
      "[82]\tvalid_0's multi_logloss: 0.162958\n",
      "[83]\tvalid_0's multi_logloss: 0.162888\n",
      "[84]\tvalid_0's multi_logloss: 0.162804\n",
      "[85]\tvalid_0's multi_logloss: 0.16271\n",
      "[86]\tvalid_0's multi_logloss: 0.162614\n",
      "[87]\tvalid_0's multi_logloss: 0.162534\n",
      "[88]\tvalid_0's multi_logloss: 0.162429\n",
      "[89]\tvalid_0's multi_logloss: 0.16237\n",
      "[90]\tvalid_0's multi_logloss: 0.162328\n",
      "[91]\tvalid_0's multi_logloss: 0.162308\n",
      "[92]\tvalid_0's multi_logloss: 0.162252\n",
      "[93]\tvalid_0's multi_logloss: 0.162154\n",
      "[94]\tvalid_0's multi_logloss: 0.162098\n",
      "[95]\tvalid_0's multi_logloss: 0.162042\n",
      "[96]\tvalid_0's multi_logloss: 0.16201\n",
      "[97]\tvalid_0's multi_logloss: 0.161984\n",
      "[98]\tvalid_0's multi_logloss: 0.161928\n",
      "[99]\tvalid_0's multi_logloss: 0.161887\n",
      "[100]\tvalid_0's multi_logloss: 0.161835\n",
      "[101]\tvalid_0's multi_logloss: 0.161826\n",
      "[102]\tvalid_0's multi_logloss: 0.161803\n",
      "[103]\tvalid_0's multi_logloss: 0.161777\n",
      "[104]\tvalid_0's multi_logloss: 0.16174\n",
      "[105]\tvalid_0's multi_logloss: 0.161698\n",
      "[106]\tvalid_0's multi_logloss: 0.161698\n",
      "[107]\tvalid_0's multi_logloss: 0.161682\n",
      "[108]\tvalid_0's multi_logloss: 0.161655\n",
      "[109]\tvalid_0's multi_logloss: 0.16162\n",
      "[110]\tvalid_0's multi_logloss: 0.161626\n",
      "[111]\tvalid_0's multi_logloss: 0.1616\n",
      "[112]\tvalid_0's multi_logloss: 0.161538\n",
      "[113]\tvalid_0's multi_logloss: 0.161535\n",
      "[114]\tvalid_0's multi_logloss: 0.161558\n",
      "[115]\tvalid_0's multi_logloss: 0.161532\n",
      "[116]\tvalid_0's multi_logloss: 0.161529\n",
      "[117]\tvalid_0's multi_logloss: 0.161527\n",
      "[118]\tvalid_0's multi_logloss: 0.161512\n",
      "[119]\tvalid_0's multi_logloss: 0.161467\n",
      "[120]\tvalid_0's multi_logloss: 0.161444\n",
      "[121]\tvalid_0's multi_logloss: 0.161438\n",
      "[122]\tvalid_0's multi_logloss: 0.161389\n",
      "[123]\tvalid_0's multi_logloss: 0.161374\n",
      "[124]\tvalid_0's multi_logloss: 0.161339\n",
      "[125]\tvalid_0's multi_logloss: 0.161372\n",
      "[126]\tvalid_0's multi_logloss: 0.161349\n",
      "[127]\tvalid_0's multi_logloss: 0.161356\n",
      "[128]\tvalid_0's multi_logloss: 0.161345\n",
      "[129]\tvalid_0's multi_logloss: 0.161332\n",
      "[130]\tvalid_0's multi_logloss: 0.161333\n",
      "[131]\tvalid_0's multi_logloss: 0.161304\n",
      "[132]\tvalid_0's multi_logloss: 0.161286\n",
      "[133]\tvalid_0's multi_logloss: 0.161285\n",
      "[134]\tvalid_0's multi_logloss: 0.16129\n",
      "[135]\tvalid_0's multi_logloss: 0.161284\n",
      "[136]\tvalid_0's multi_logloss: 0.161272\n",
      "[137]\tvalid_0's multi_logloss: 0.161267\n",
      "[138]\tvalid_0's multi_logloss: 0.161244\n",
      "[139]\tvalid_0's multi_logloss: 0.161238\n",
      "[140]\tvalid_0's multi_logloss: 0.161229\n",
      "[141]\tvalid_0's multi_logloss: 0.161233\n",
      "[142]\tvalid_0's multi_logloss: 0.161217\n",
      "[143]\tvalid_0's multi_logloss: 0.16119\n",
      "[144]\tvalid_0's multi_logloss: 0.161184\n",
      "[145]\tvalid_0's multi_logloss: 0.161155\n",
      "[146]\tvalid_0's multi_logloss: 0.161147\n",
      "[147]\tvalid_0's multi_logloss: 0.16117\n",
      "[148]\tvalid_0's multi_logloss: 0.161161\n",
      "[149]\tvalid_0's multi_logloss: 0.161172\n",
      "[150]\tvalid_0's multi_logloss: 0.16116\n",
      "[151]\tvalid_0's multi_logloss: 0.161153\n",
      "[152]\tvalid_0's multi_logloss: 0.161155\n",
      "[153]\tvalid_0's multi_logloss: 0.161156\n",
      "[154]\tvalid_0's multi_logloss: 0.16114\n",
      "[155]\tvalid_0's multi_logloss: 0.161148\n",
      "[156]\tvalid_0's multi_logloss: 0.16115\n",
      "[157]\tvalid_0's multi_logloss: 0.161165\n",
      "[158]\tvalid_0's multi_logloss: 0.161158\n",
      "[159]\tvalid_0's multi_logloss: 0.161172\n",
      "[160]\tvalid_0's multi_logloss: 0.161169\n",
      "[161]\tvalid_0's multi_logloss: 0.161172\n",
      "[162]\tvalid_0's multi_logloss: 0.161187\n",
      "[163]\tvalid_0's multi_logloss: 0.161193\n",
      "[164]\tvalid_0's multi_logloss: 0.161188\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's multi_logloss: 0.16114\n",
      "training model for CV #5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.652, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.652\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1761578431285439e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1761578431285439e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.745594805270928, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.745594805270928\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\bryan\\anaconda3\\envs\\py37\\lib\\site-packages\\lightgbm\\engine.py:153: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.858353\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's multi_logloss: 0.757297\n",
      "[3]\tvalid_0's multi_logloss: 0.672288\n",
      "[4]\tvalid_0's multi_logloss: 0.601153\n",
      "[5]\tvalid_0's multi_logloss: 0.542892\n",
      "[6]\tvalid_0's multi_logloss: 0.502706\n",
      "[7]\tvalid_0's multi_logloss: 0.466624\n",
      "[8]\tvalid_0's multi_logloss: 0.439641\n",
      "[9]\tvalid_0's multi_logloss: 0.411545\n",
      "[10]\tvalid_0's multi_logloss: 0.383336\n",
      "[11]\tvalid_0's multi_logloss: 0.358572\n",
      "[12]\tvalid_0's multi_logloss: 0.33726\n",
      "[13]\tvalid_0's multi_logloss: 0.319002\n",
      "[14]\tvalid_0's multi_logloss: 0.303098\n",
      "[15]\tvalid_0's multi_logloss: 0.291061\n",
      "[16]\tvalid_0's multi_logloss: 0.278477\n",
      "[17]\tvalid_0's multi_logloss: 0.267449\n",
      "[18]\tvalid_0's multi_logloss: 0.257356\n",
      "[19]\tvalid_0's multi_logloss: 0.248658\n",
      "[20]\tvalid_0's multi_logloss: 0.24179\n",
      "[21]\tvalid_0's multi_logloss: 0.234386\n",
      "[22]\tvalid_0's multi_logloss: 0.228849\n",
      "[23]\tvalid_0's multi_logloss: 0.222086\n",
      "[24]\tvalid_0's multi_logloss: 0.217684\n",
      "[25]\tvalid_0's multi_logloss: 0.212969\n",
      "[26]\tvalid_0's multi_logloss: 0.209609\n",
      "[27]\tvalid_0's multi_logloss: 0.205956\n",
      "[28]\tvalid_0's multi_logloss: 0.202949\n",
      "[29]\tvalid_0's multi_logloss: 0.19934\n",
      "[30]\tvalid_0's multi_logloss: 0.197019\n",
      "[31]\tvalid_0's multi_logloss: 0.194068\n",
      "[32]\tvalid_0's multi_logloss: 0.191484\n",
      "[33]\tvalid_0's multi_logloss: 0.188713\n",
      "[34]\tvalid_0's multi_logloss: 0.18624\n",
      "[35]\tvalid_0's multi_logloss: 0.183874\n",
      "[36]\tvalid_0's multi_logloss: 0.182662\n",
      "[37]\tvalid_0's multi_logloss: 0.181603\n",
      "[38]\tvalid_0's multi_logloss: 0.180052\n",
      "[39]\tvalid_0's multi_logloss: 0.178905\n",
      "[40]\tvalid_0's multi_logloss: 0.177908\n",
      "[41]\tvalid_0's multi_logloss: 0.176689\n",
      "[42]\tvalid_0's multi_logloss: 0.175549\n",
      "[43]\tvalid_0's multi_logloss: 0.174511\n",
      "[44]\tvalid_0's multi_logloss: 0.173435\n",
      "[45]\tvalid_0's multi_logloss: 0.172808\n",
      "[46]\tvalid_0's multi_logloss: 0.172183\n",
      "[47]\tvalid_0's multi_logloss: 0.171549\n",
      "[48]\tvalid_0's multi_logloss: 0.170921\n",
      "[49]\tvalid_0's multi_logloss: 0.170062\n",
      "[50]\tvalid_0's multi_logloss: 0.169548\n",
      "[51]\tvalid_0's multi_logloss: 0.168856\n",
      "[52]\tvalid_0's multi_logloss: 0.168401\n",
      "[53]\tvalid_0's multi_logloss: 0.167823\n",
      "[54]\tvalid_0's multi_logloss: 0.167676\n",
      "[55]\tvalid_0's multi_logloss: 0.167382\n",
      "[56]\tvalid_0's multi_logloss: 0.167015\n",
      "[57]\tvalid_0's multi_logloss: 0.166691\n",
      "[58]\tvalid_0's multi_logloss: 0.166419\n",
      "[59]\tvalid_0's multi_logloss: 0.166087\n",
      "[60]\tvalid_0's multi_logloss: 0.165737\n",
      "[61]\tvalid_0's multi_logloss: 0.165406\n",
      "[62]\tvalid_0's multi_logloss: 0.165254\n",
      "[63]\tvalid_0's multi_logloss: 0.1649\n",
      "[64]\tvalid_0's multi_logloss: 0.164527\n",
      "[65]\tvalid_0's multi_logloss: 0.164281\n",
      "[66]\tvalid_0's multi_logloss: 0.164012\n",
      "[67]\tvalid_0's multi_logloss: 0.163669\n",
      "[68]\tvalid_0's multi_logloss: 0.163421\n",
      "[69]\tvalid_0's multi_logloss: 0.163187\n",
      "[70]\tvalid_0's multi_logloss: 0.162956\n",
      "[71]\tvalid_0's multi_logloss: 0.162801\n",
      "[72]\tvalid_0's multi_logloss: 0.162658\n",
      "[73]\tvalid_0's multi_logloss: 0.16247\n",
      "[74]\tvalid_0's multi_logloss: 0.162358\n",
      "[75]\tvalid_0's multi_logloss: 0.162229\n",
      "[76]\tvalid_0's multi_logloss: 0.162051\n",
      "[77]\tvalid_0's multi_logloss: 0.161951\n",
      "[78]\tvalid_0's multi_logloss: 0.161868\n",
      "[79]\tvalid_0's multi_logloss: 0.161685\n",
      "[80]\tvalid_0's multi_logloss: 0.16163\n",
      "[81]\tvalid_0's multi_logloss: 0.16151\n",
      "[82]\tvalid_0's multi_logloss: 0.161364\n",
      "[83]\tvalid_0's multi_logloss: 0.161251\n",
      "[84]\tvalid_0's multi_logloss: 0.161181\n",
      "[85]\tvalid_0's multi_logloss: 0.161075\n",
      "[86]\tvalid_0's multi_logloss: 0.160951\n",
      "[87]\tvalid_0's multi_logloss: 0.160898\n",
      "[88]\tvalid_0's multi_logloss: 0.160808\n",
      "[89]\tvalid_0's multi_logloss: 0.160761\n",
      "[90]\tvalid_0's multi_logloss: 0.160724\n",
      "[91]\tvalid_0's multi_logloss: 0.160704\n",
      "[92]\tvalid_0's multi_logloss: 0.160665\n",
      "[93]\tvalid_0's multi_logloss: 0.160588\n",
      "[94]\tvalid_0's multi_logloss: 0.160508\n",
      "[95]\tvalid_0's multi_logloss: 0.160467\n",
      "[96]\tvalid_0's multi_logloss: 0.160408\n",
      "[97]\tvalid_0's multi_logloss: 0.160361\n",
      "[98]\tvalid_0's multi_logloss: 0.160328\n",
      "[99]\tvalid_0's multi_logloss: 0.160286\n",
      "[100]\tvalid_0's multi_logloss: 0.160246\n",
      "[101]\tvalid_0's multi_logloss: 0.160237\n",
      "[102]\tvalid_0's multi_logloss: 0.160195\n",
      "[103]\tvalid_0's multi_logloss: 0.160163\n",
      "[104]\tvalid_0's multi_logloss: 0.160178\n",
      "[105]\tvalid_0's multi_logloss: 0.160154\n",
      "[106]\tvalid_0's multi_logloss: 0.160128\n",
      "[107]\tvalid_0's multi_logloss: 0.160093\n",
      "[108]\tvalid_0's multi_logloss: 0.160063\n",
      "[109]\tvalid_0's multi_logloss: 0.160026\n",
      "[110]\tvalid_0's multi_logloss: 0.160042\n",
      "[111]\tvalid_0's multi_logloss: 0.160024\n",
      "[112]\tvalid_0's multi_logloss: 0.159995\n",
      "[113]\tvalid_0's multi_logloss: 0.159996\n",
      "[114]\tvalid_0's multi_logloss: 0.160007\n",
      "[115]\tvalid_0's multi_logloss: 0.160007\n",
      "[116]\tvalid_0's multi_logloss: 0.160002\n",
      "[117]\tvalid_0's multi_logloss: 0.159948\n",
      "[118]\tvalid_0's multi_logloss: 0.159921\n",
      "[119]\tvalid_0's multi_logloss: 0.159913\n",
      "[120]\tvalid_0's multi_logloss: 0.159909\n",
      "[121]\tvalid_0's multi_logloss: 0.159871\n",
      "[122]\tvalid_0's multi_logloss: 0.159874\n",
      "[123]\tvalid_0's multi_logloss: 0.159843\n",
      "[124]\tvalid_0's multi_logloss: 0.15986\n",
      "[125]\tvalid_0's multi_logloss: 0.159839\n",
      "[126]\tvalid_0's multi_logloss: 0.159842\n",
      "[127]\tvalid_0's multi_logloss: 0.159822\n",
      "[128]\tvalid_0's multi_logloss: 0.159816\n",
      "[129]\tvalid_0's multi_logloss: 0.159808\n",
      "[130]\tvalid_0's multi_logloss: 0.159814\n",
      "[131]\tvalid_0's multi_logloss: 0.159805\n",
      "[132]\tvalid_0's multi_logloss: 0.159801\n",
      "[133]\tvalid_0's multi_logloss: 0.159801\n",
      "[134]\tvalid_0's multi_logloss: 0.159787\n",
      "[135]\tvalid_0's multi_logloss: 0.159785\n",
      "[136]\tvalid_0's multi_logloss: 0.159781\n",
      "[137]\tvalid_0's multi_logloss: 0.159778\n",
      "[138]\tvalid_0's multi_logloss: 0.159792\n",
      "[139]\tvalid_0's multi_logloss: 0.159782\n",
      "[140]\tvalid_0's multi_logloss: 0.159756\n",
      "[141]\tvalid_0's multi_logloss: 0.159757\n",
      "[142]\tvalid_0's multi_logloss: 0.159758\n",
      "[143]\tvalid_0's multi_logloss: 0.159768\n",
      "[144]\tvalid_0's multi_logloss: 0.159765\n",
      "[145]\tvalid_0's multi_logloss: 0.159762\n",
      "[146]\tvalid_0's multi_logloss: 0.159742\n",
      "[147]\tvalid_0's multi_logloss: 0.159719\n",
      "[148]\tvalid_0's multi_logloss: 0.159695\n",
      "[149]\tvalid_0's multi_logloss: 0.159711\n",
      "[150]\tvalid_0's multi_logloss: 0.159695\n",
      "[151]\tvalid_0's multi_logloss: 0.159723\n",
      "[152]\tvalid_0's multi_logloss: 0.159704\n",
      "[153]\tvalid_0's multi_logloss: 0.1597\n",
      "[154]\tvalid_0's multi_logloss: 0.159671\n",
      "[155]\tvalid_0's multi_logloss: 0.159652\n",
      "[156]\tvalid_0's multi_logloss: 0.159662\n",
      "[157]\tvalid_0's multi_logloss: 0.159663\n",
      "[158]\tvalid_0's multi_logloss: 0.159655\n",
      "[159]\tvalid_0's multi_logloss: 0.159652\n",
      "[160]\tvalid_0's multi_logloss: 0.159662\n",
      "[161]\tvalid_0's multi_logloss: 0.159641\n",
      "[162]\tvalid_0's multi_logloss: 0.159651\n",
      "[163]\tvalid_0's multi_logloss: 0.159648\n",
      "[164]\tvalid_0's multi_logloss: 0.159668\n",
      "[165]\tvalid_0's multi_logloss: 0.15967\n",
      "[166]\tvalid_0's multi_logloss: 0.15967\n",
      "[167]\tvalid_0's multi_logloss: 0.159668\n",
      "[168]\tvalid_0's multi_logloss: 0.15967\n",
      "[169]\tvalid_0's multi_logloss: 0.159658\n",
      "[170]\tvalid_0's multi_logloss: 0.159648\n",
      "[171]\tvalid_0's multi_logloss: 0.159654\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 0.159641\n"
     ]
    }
   ],
   "source": [
    "p_val = np.zeros((trn.shape[0], n_class))\n",
    "p_tst = np.zeros((tst.shape[0], n_class))\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(trn, y), 1):\n",
    "    print(f'training model for CV #{i}')\n",
    "    clf = LGBMClassifier(**params)\n",
    "    clf.fit(trn[i_trn], y[i_trn],\n",
    "            eval_set=[(trn[i_val], y[i_val])],\n",
    "            eval_metric='multiclass',\n",
    "            early_stopping_rounds=10)\n",
    "    \n",
    "    p_val[i_val, :] = clf.predict_proba(trn[i_val])\n",
    "    p_tst += clf.predict_proba(tst) / n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.2753%\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy_score(y, np.argmax(p_val, axis=1)) * 100:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320000, 3) (80000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(p_val.shape, p_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking에 사용\n",
    "np.savetxt(p_val_file, p_val, fmt='%.6f', delimiter=',')\n",
    "np.savetxt(p_tst_file, p_tst, fmt='%.6f', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='feature'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imp = pd.DataFrame({'feature': df.columns, 'importance': clf.feature_importances_})\n",
    "imp = imp.sort_values('importance').set_index('feature')\n",
    "imp.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320000</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320002</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320003</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320004</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class\n",
       "id           \n",
       "320000      0\n",
       "320001      0\n",
       "320002      0\n",
       "320003      0\n",
       "320004      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(sample_file, index_col=0)\n",
    "print(sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>320000</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320001</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320002</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320003</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320004</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class\n",
       "id           \n",
       "320000      2\n",
       "320001      0\n",
       "320002      2\n",
       "320003      0\n",
       "320004      2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[target_col] = np.argmax(p_tst, axis=1)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    40991\n",
       "0    29967\n",
       "1     9042\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[target_col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(sub_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
